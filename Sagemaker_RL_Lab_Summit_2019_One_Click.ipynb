{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sagemaker RL Lab - Summit 2019 - One Click.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0Zv-79trOkkx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sagemaker RL Lab - Summit  - \"One Click!\""
      ]
    },
    {
      "metadata": {
        "id": "gbqo0hk7Ornl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Hi! Run the code cell below:\n",
        "\n",
        "\n",
        "\n",
        "1.  First select the code cell by simply left clicking on it below, when you select it - it should go green as follows:\n",
        "\n",
        "![alt text](https://i.ibb.co/rt9NdXL/Screen-Shot-2019-03-25-at-2-02-08-pm.png)\n",
        "\n",
        "2.   Once the cell is selected, click the \"run\" button at the top of the notebook, which looks like this:\n",
        "\n",
        "![alt text](https://i.ibb.co/fCwfvBk/Screen-Shot-2019-03-25-at-2-05-33-pm.png)\n",
        "\n",
        "This will start our model's training process. We will spend the rest of this lab explaining what is going on here line by line - with an amazing result to follow!\n",
        "\n",
        "Please open the additional notebook \"Sagemaker RL Lab - Summit 2019 - Explanation\" now!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OJb-2Dufmqs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90201
        },
        "outputId": "3051beae-ffbc-4347-a018-83d9aa46b658"
      },
      "cell_type": "code",
      "source": [
        "!pip install ray[rllib]\n",
        "!pip install ray[debug]\n",
        "\n",
        "import ray\n",
        "import ray.rllib.agents.impala as impala\n",
        "from ray.tune.logger import pretty_print\n",
        "\n",
        "ray.init()\n",
        "\n",
        "config = impala.DEFAULT_CONFIG.copy()\n",
        "config[\"num_gpus\"] = 1\n",
        "config[\"num_workers\"] = 2\n",
        "agent = impala.ImpalaAgent(config=config, env=\"BreakoutDeterministic-v4\") \n",
        "\n",
        "\n",
        "for i in range(10000):\n",
        "   # Perform one iteration of training the policy with IMPALA\n",
        "   result = agent.train()\n",
        "   print(pretty_print(result))\n",
        "\n",
        "   if i % 100 == 0:\n",
        "       checkpoint = agent.save()\n",
        "       print(\"checkpoint saved at\", checkpoint)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ray[rllib]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/71/6a054e563cb7c3307e1bb059fabb87bbff0909aeee0d60dc1d5fee677e18/ray-0.6.4-cp36-cp36m-manylinux1_x86_64.whl (75.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 75.0MB 593kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.6.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (7.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.6.6)\n",
            "Collecting flatbuffers (from ray[rllib])\n",
            "  Downloading https://files.pythonhosted.org/packages/21/9a/b0f3302f994b58bc26ebcc39218c14e33d8fa1bd96b7ba709597aff7507c/flatbuffers-1.10-py2.py3-none-any.whl\n",
            "Collecting redis (from ray[rllib])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a7/cff10cc5f1180834a3ed564d148fb4329c989cbb1f2e196fc9a10fa07072/redis-3.2.1-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 24.6MB/s \n",
            "\u001b[?25hCollecting funcsigs (from ray[rllib])\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.13)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.14.6)\n",
            "Collecting colorama (from ray[rllib])\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (3.0.10)\n",
            "Requirement already satisfied: gym[atari]; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (0.10.11)\n",
            "Requirement already satisfied: scipy; extra == \"rllib\" in /usr/local/lib/python3.6/dist-packages (from ray[rllib]) (1.1.0)\n",
            "Collecting opencv-python-headless; extra == \"rllib\" (from ray[rllib])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ca/825032d6a5c13dd6e0c74bf14d1a2c18d1089db1926f7d9c5ce3df50cc1c/opencv_python_headless-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (18.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 18.8MB 2.7MB/s \n",
            "\u001b[?25hCollecting lz4; extra == \"rllib\" (from ray[rllib])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/fe/66da85ed881031de7cf7de9dd38cc98aec8859824c7bcd3e8a88d255f36d/lz4-2.1.6-cp36-cp36m-manylinux1_x86_64.whl (359kB)\n",
            "\u001b[K    100% |████████████████████████████████| 368kB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (40.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (19.1.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[rllib]) (1.8.0)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (2.18.4)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (1.3.2)\n",
            "Requirement already satisfied: atari_py>=0.1.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (0.1.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (4.1.1)\n",
            "Requirement already satisfied: PyOpenGL in /usr/local/lib/python3.6/dist-packages (from gym[atari]; extra == \"rllib\"->ray[rllib]) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.16.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->gym[atari]; extra == \"rllib\"->ray[rllib]) (0.46)\n",
            "Installing collected packages: flatbuffers, redis, funcsigs, colorama, opencv-python-headless, lz4, ray\n",
            "Successfully installed colorama-0.4.1 flatbuffers-1.10 funcsigs-1.0.2 lz4-2.1.6 opencv-python-headless-4.0.0.21 ray-0.6.4 redis-3.2.1\n",
            "Requirement already satisfied: ray[debug] in /usr/local/lib/python3.6/dist-packages (0.6.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (7.0)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (3.0.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (0.4.1)\n",
            "Requirement already satisfied: funcsigs in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (1.0.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (3.6.4)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (3.6.6)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (3.2.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (1.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (3.13)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (1.14.6)\n",
            "Collecting py-spy; extra == \"debug\" (from ray[debug])\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/c2/bacd6ff83b43e1eff51d0d93a1fc930daad02fa93c0499d6facece57f786/py_spy-0.1.10-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.9MB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil; extra == \"debug\" in /usr/local/lib/python3.6/dist-packages (from ray[debug]) (5.4.8)\n",
            "Collecting setproctitle; extra == \"debug\" (from ray[debug])\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/0d/dc0d2234aacba6cf1a729964383e3452c52096dc695581248b548786f2b3/setproctitle-1.1.10.tar.gz\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]) (19.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]) (1.8.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]) (6.0.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]) (1.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->ray[debug]) (40.8.0)\n",
            "Building wheels for collected packages: setproctitle\n",
            "  Building wheel for setproctitle (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/e6/b1/a6/9719530228e258eba904501fef99d5d85c80d52bd8f14438a3\n",
            "Successfully built setproctitle\n",
            "Installing collected packages: py-spy, setproctitle\n",
            "Successfully installed py-spy-0.1.10 setproctitle-1.1.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-03-25 03:11:34,364\tINFO node.py:439 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-03-25_03-11-34_206/logs.\n",
            "2019-03-25 03:11:34,480\tINFO services.py:364 -- Waiting for redis server at 127.0.0.1:18239 to respond...\n",
            "2019-03-25 03:11:34,616\tINFO services.py:364 -- Waiting for redis server at 127.0.0.1:43755 to respond...\n",
            "2019-03-25 03:11:34,624\tINFO services.py:761 -- Starting Redis shard with 2.52 GB max memory.\n",
            "2019-03-25 03:11:34,673\tINFO services.py:1449 -- Starting the Plasma object store with 3.78 GB memory using /dev/shm.\n",
            "2019-03-25 03:11:35,951\tINFO policy_evaluator.py:275 -- Creating policy evaluation worker 0 on CPU (please ignore any CUDA init errors)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ray/rllib/models/action_dist.py:114: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.random.categorical instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ray/rllib/agents/impala/vtrace_policy_graph.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:307: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:352: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46,232\tINFO policy_evaluator.py:275 -- Creating policy evaluation worker 2 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.241333: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.241599: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x6037b80 executing computations on platform Host. Devices:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.241631: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.246452: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.246530: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: 228cabdf7ba8\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.246552: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: 228cabdf7ba8\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.246638: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 410.79.0\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.246687: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 410.79.0\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m 2019-03-25 03:11:46.246704: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 410.79.0\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Colocations handled automatically by placer.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46,299\tINFO policy_evaluator.py:275 -- Creating policy evaluation worker 1 on CPU (please ignore any CUDA init errors)\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.310330: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.310625: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x64ffb80 executing computations on platform Host. Devices:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.310662: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.316669: E tensorflow/stream_executor/cuda/cuda_driver.cc:300] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.316740: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:161] retrieving CUDA diagnostic information for host: 228cabdf7ba8\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.316767: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:168] hostname: 228cabdf7ba8\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.316853: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:192] libcuda reported version is: 410.79.0\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.316913: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:196] kernel reported version is: 410.79.0\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m 2019-03-25 03:11:46.316939: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:303] kernel version seems to match DSO: 410.79.0\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Colocations handled automatically by placer.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ray/rllib/models/action_dist.py:114: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Use tf.random.categorical instead.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ray/rllib/models/action_dist.py:114: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Use tf.random.categorical instead.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ray/rllib/agents/impala/vtrace_policy_graph.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ray/rllib/agents/impala/vtrace_policy_graph.py:75: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:307: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:352: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:307: to_double (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/sample_stats.py:352: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Use tf.cast instead.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m   \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=297)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=298)\u001b[0m Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-11-50\n",
            "done: false\n",
            "episode_len_mean: 144.5\n",
            "episode_reward_max: 0.0\n",
            "episode_reward_mean: 0.0\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 4\n",
            "episodes_total: 4\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner_queue:\n",
            "    size_count: 0\n",
            "    size_mean: .nan\n",
            "    size_quantiles: []\n",
            "    size_std: .nan\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 400\n",
            "  num_steps_trained: 0\n",
            "  num_weight_syncs: 8\n",
            "  sample_throughput: 36.58\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: .nan\n",
            "    learner_grad_time_ms: .nan\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.627\n",
            "iterations_since_restore: 1\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 10.48203182220459\n",
            "time_this_iter_s: 10.48203182220459\n",
            "time_total_s: 10.48203182220459\n",
            "timestamp: 1553483510\n",
            "timesteps_since_restore: 400\n",
            "timesteps_this_iter: 400\n",
            "timesteps_total: 400\n",
            "training_iteration: 1\n",
            "\n",
            "checkpoint saved at /root/ray_results/IMPALA_BreakoutDeterministic-v4_2019-03-25_03-11-34z3qzli5w/checkpoint_1/checkpoint-1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ray/tune/logger.py:258: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  if np.issubdtype(value, float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-12-01\n",
            "done: false\n",
            "episode_len_mean: 158.66666666666666\n",
            "episode_reward_max: 2.0\n",
            "episode_reward_mean: 0.5\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 24\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 0.0\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0\n",
            "    mean_KL: 0.0\n",
            "    median_KL: 0.0\n",
            "    model: {}\n",
            "    policy_loss: -0.0\n",
            "    var_gnorm: 9.722892761230469\n",
            "    vf_explained_var: 0.000356137752532959\n",
            "    vf_loss: 1912592.25\n",
            "  learner_queue:\n",
            "    size_count: 6\n",
            "    size_mean: 1.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.5\n",
            "    - 2.5\n",
            "    - 3.0\n",
            "    size_std: 1.1547005383792515\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 3100\n",
            "  num_steps_trained: 3000\n",
            "  num_weight_syncs: 62\n",
            "  sample_throughput: 258.159\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 2292.355\n",
            "    learner_grad_time_ms: 1142.885\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 10.921\n",
            "  train_throughput: 140.228\n",
            "iterations_since_restore: 2\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 20.913752555847168\n",
            "time_this_iter_s: 10.431720733642578\n",
            "time_total_s: 20.913752555847168\n",
            "timestamp: 1553483521\n",
            "timesteps_since_restore: 3100\n",
            "timesteps_this_iter: 2700\n",
            "timesteps_total: 3100\n",
            "training_iteration: 2\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-12-11\n",
            "done: false\n",
            "episode_len_mean: 182.1951219512195\n",
            "episode_reward_max: 2.0\n",
            "episode_reward_mean: 1.1219512195121952\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 17\n",
            "episodes_total: 41\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 0.0\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0\n",
            "    mean_KL: 0.0\n",
            "    median_KL: 0.0\n",
            "    model: {}\n",
            "    policy_loss: -0.0\n",
            "    var_gnorm: 9.780160903930664\n",
            "    vf_explained_var: 0.0029239654541015625\n",
            "    vf_loss: 55409.3125\n",
            "  learner_queue:\n",
            "    size_count: 12\n",
            "    size_mean: 0.5\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 1.9000000000000004\n",
            "    - 3.0\n",
            "    size_std: 0.9574271077563381\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 6350\n",
            "  num_steps_trained: 6000\n",
            "  num_weight_syncs: 127\n",
            "  sample_throughput: 306.812\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1164.723\n",
            "    learner_grad_time_ms: 143.954\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.37\n",
            "  train_throughput: 283.211\n",
            "iterations_since_restore: 3\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 31.494200944900513\n",
            "time_this_iter_s: 10.580448389053345\n",
            "time_total_s: 31.494200944900513\n",
            "timestamp: 1553483531\n",
            "timesteps_since_restore: 6350\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 6350\n",
            "training_iteration: 3\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-12-22\n",
            "done: false\n",
            "episode_len_mean: 192.8793103448276\n",
            "episode_reward_max: 2.0\n",
            "episode_reward_mean: 1.3793103448275863\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 17\n",
            "episodes_total: 58\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 0.0\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0\n",
            "    mean_KL: 0.0\n",
            "    median_KL: 0.0\n",
            "    model: {}\n",
            "    policy_loss: 0.0\n",
            "    var_gnorm: 9.84331226348877\n",
            "    vf_explained_var: -0.008330941200256348\n",
            "    vf_loss: 5302.6513671875\n",
            "  learner_queue:\n",
            "    size_count: 19\n",
            "    size_mean: 0.3157894736842105\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 1.1999999999999993\n",
            "    - 3.0\n",
            "    size_std: 0.7981974151633211\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 9550\n",
            "  num_steps_trained: 9500\n",
            "  num_weight_syncs: 191\n",
            "  sample_throughput: 307.493\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1496.331\n",
            "    learner_grad_time_ms: 151.977\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 28.271\n",
            "  train_throughput: 336.32\n",
            "iterations_since_restore: 4\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 41.89042925834656\n",
            "time_this_iter_s: 10.396228313446045\n",
            "time_total_s: 41.89042925834656\n",
            "timestamp: 1553483542\n",
            "timesteps_since_restore: 9550\n",
            "timesteps_this_iter: 3200\n",
            "timesteps_total: 9550\n",
            "training_iteration: 4\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-12-32\n",
            "done: false\n",
            "episode_len_mean: 198.8684210526316\n",
            "episode_reward_max: 2.0\n",
            "episode_reward_mean: 1.5263157894736843\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 76\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 5.020950425175738e-14\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 3.896777720821369e-17\n",
            "    mean_KL: 7.518725179430362e-18\n",
            "    median_KL: 1.6606222563386135e-23\n",
            "    model: {}\n",
            "    policy_loss: -0.0\n",
            "    var_gnorm: 9.883384704589844\n",
            "    vf_explained_var: 0.09880024194717407\n",
            "    vf_loss: 113.44032287597656\n",
            "  learner_queue:\n",
            "    size_count: 25\n",
            "    size_mean: 0.24\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.6000000000000014\n",
            "    - 3.0\n",
            "    size_std: 0.7088018058667741\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 12750\n",
            "  num_steps_trained: 12500\n",
            "  num_weight_syncs: 255\n",
            "  sample_throughput: 307.146\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1468.74\n",
            "    learner_grad_time_ms: 148.593\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.344\n",
            "  train_throughput: 287.95\n",
            "iterations_since_restore: 5\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 52.297160387039185\n",
            "time_this_iter_s: 10.406731128692627\n",
            "time_total_s: 52.297160387039185\n",
            "timestamp: 1553483552\n",
            "timesteps_since_restore: 12750\n",
            "timesteps_this_iter: 3200\n",
            "timesteps_total: 12750\n",
            "training_iteration: 5\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-12-43\n",
            "done: false\n",
            "episode_len_mean: 201.01063829787233\n",
            "episode_reward_max: 2.0\n",
            "episode_reward_mean: 1.6170212765957446\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 94\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 0.08456739783287048\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 6.200934149092063e-05\n",
            "    mean_KL: 1.527516906207893e-05\n",
            "    median_KL: 1.0240500808444963e-10\n",
            "    model: {}\n",
            "    policy_loss: -0.0005901571130380034\n",
            "    var_gnorm: 9.922844886779785\n",
            "    vf_explained_var: 0.36248087882995605\n",
            "    vf_loss: 49.233638763427734\n",
            "  learner_queue:\n",
            "    size_count: 32\n",
            "    size_mean: 0.1875\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 3.0\n",
            "    size_std: 0.6343057228182637\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 16000\n",
            "  num_steps_trained: 15500\n",
            "  num_weight_syncs: 320\n",
            "  sample_throughput: 308.843\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1471.837\n",
            "    learner_grad_time_ms: 146.68\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 16.233\n",
            "  train_throughput: 285.086\n",
            "iterations_since_restore: 6\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 62.80895638465881\n",
            "time_this_iter_s: 10.511795997619629\n",
            "time_total_s: 62.80895638465881\n",
            "timestamp: 1553483563\n",
            "timesteps_since_restore: 16000\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 16000\n",
            "training_iteration: 6\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-12-53\n",
            "done: false\n",
            "episode_len_mean: 210.22\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.87\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 17\n",
            "episodes_total: 111\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 15.25326156616211\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0009816864039748907\n",
            "    mean_KL: 0.0001911798754008487\n",
            "    median_KL: 7.287593639659917e-09\n",
            "    model: {}\n",
            "    policy_loss: 1.271512746810913\n",
            "    var_gnorm: 9.96584701538086\n",
            "    vf_explained_var: 0.6224713325500488\n",
            "    vf_loss: 28.36841583251953\n",
            "  learner_queue:\n",
            "    size_count: 38\n",
            "    size_mean: 0.15789473684210525\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 3.0\n",
            "    size_std: 0.5860804592452655\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 19250\n",
            "  num_steps_trained: 19000\n",
            "  num_weight_syncs: 385\n",
            "  sample_throughput: 311.248\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1455.057\n",
            "    learner_grad_time_ms: 143.972\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.615\n",
            "  train_throughput: 335.19\n",
            "iterations_since_restore: 7\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 73.23983931541443\n",
            "time_this_iter_s: 10.430882930755615\n",
            "time_total_s: 73.23983931541443\n",
            "timestamp: 1553483573\n",
            "timesteps_since_restore: 19250\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 19250\n",
            "training_iteration: 7\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-13-04\n",
            "done: false\n",
            "episode_len_mean: 213.16\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.95\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 129\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 35.02736282348633\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.005156317725777626\n",
            "    mean_KL: 0.0007580863311886787\n",
            "    median_KL: 5.083867904431827e-08\n",
            "    model: {}\n",
            "    policy_loss: -9.32303237915039\n",
            "    var_gnorm: 10.023702621459961\n",
            "    vf_explained_var: 0.7670299410820007\n",
            "    vf_loss: 22.11655044555664\n",
            "  learner_queue:\n",
            "    size_count: 45\n",
            "    size_mean: 0.13333333333333333\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 3.0\n",
            "    size_std: 0.541602560309064\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 22500\n",
            "  num_steps_trained: 22000\n",
            "  num_weight_syncs: 450\n",
            "  sample_throughput: 307.014\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1474.077\n",
            "    learner_grad_time_ms: 145.752\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 18.833\n",
            "  train_throughput: 283.398\n",
            "iterations_since_restore: 8\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 83.81210780143738\n",
            "time_this_iter_s: 10.57226848602295\n",
            "time_total_s: 83.81210780143738\n",
            "timestamp: 1553483584\n",
            "timesteps_since_restore: 22500\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 22500\n",
            "training_iteration: 8\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-13-14\n",
            "done: false\n",
            "episode_len_mean: 213.35\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.96\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 17\n",
            "episodes_total: 146\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 72.7533187866211\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.01979631558060646\n",
            "    mean_KL: 0.004487972240895033\n",
            "    median_KL: 1.0104177761149913e-07\n",
            "    model: {}\n",
            "    policy_loss: 2.456164598464966\n",
            "    var_gnorm: 10.078164100646973\n",
            "    vf_explained_var: 0.8247774839401245\n",
            "    vf_loss: 18.227489471435547\n",
            "  learner_queue:\n",
            "    size_count: 51\n",
            "    size_mean: 0.06\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 2.0\n",
            "    size_std: 0.31048349392520047\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 25750\n",
            "  num_steps_trained: 25500\n",
            "  num_weight_syncs: 515\n",
            "  sample_throughput: 309.351\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1487.445\n",
            "    learner_grad_time_ms: 147.098\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 12.908\n",
            "  train_throughput: 333.147\n",
            "iterations_since_restore: 9\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 94.30712842941284\n",
            "time_this_iter_s: 10.495020627975464\n",
            "time_total_s: 94.30712842941284\n",
            "timestamp: 1553483594\n",
            "timesteps_since_restore: 25750\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 25750\n",
            "training_iteration: 9\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-13-24\n",
            "done: false\n",
            "episode_len_mean: 211.67\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.92\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 164\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 121.36024475097656\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0018232350703328848\n",
            "    mean_KL: 0.0002933560172095895\n",
            "    median_KL: 1.0846331122138508e-07\n",
            "    model: {}\n",
            "    policy_loss: -25.50163459777832\n",
            "    var_gnorm: 10.125160217285156\n",
            "    vf_explained_var: 0.6002923250198364\n",
            "    vf_loss: 30.418346405029297\n",
            "  learner_queue:\n",
            "    size_count: 57\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 28950\n",
            "  num_steps_trained: 28500\n",
            "  num_weight_syncs: 579\n",
            "  sample_throughput: 308.582\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1483.003\n",
            "    learner_grad_time_ms: 144.127\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.359\n",
            "  train_throughput: 289.295\n",
            "iterations_since_restore: 10\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 104.66463112831116\n",
            "time_this_iter_s: 10.357502698898315\n",
            "time_total_s: 104.66463112831116\n",
            "timestamp: 1553483604\n",
            "timesteps_since_restore: 28950\n",
            "timesteps_this_iter: 3200\n",
            "timesteps_total: 28950\n",
            "training_iteration: 10\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-13-35\n",
            "done: false\n",
            "episode_len_mean: 212.62\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.93\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 182\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 209.2891082763672\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.027220409363508224\n",
            "    mean_KL: 0.004593603312969208\n",
            "    median_KL: 1.7694857490369031e-07\n",
            "    model: {}\n",
            "    policy_loss: -10.039859771728516\n",
            "    var_gnorm: 10.170674324035645\n",
            "    vf_explained_var: 0.8825187683105469\n",
            "    vf_loss: 8.921612739562988\n",
            "  learner_queue:\n",
            "    size_count: 64\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 32200\n",
            "  num_steps_trained: 32000\n",
            "  num_weight_syncs: 644\n",
            "  sample_throughput: 308.106\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1481.349\n",
            "    learner_grad_time_ms: 144.111\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.622\n",
            "  train_throughput: 331.806\n",
            "iterations_since_restore: 11\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 115.20293045043945\n",
            "time_this_iter_s: 10.538299322128296\n",
            "time_total_s: 115.20293045043945\n",
            "timestamp: 1553483615\n",
            "timesteps_since_restore: 32200\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 32200\n",
            "training_iteration: 11\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-13-46\n",
            "done: false\n",
            "episode_len_mean: 214.05\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.93\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 16\n",
            "episodes_total: 198\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 348.3259582519531\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.024290651082992554\n",
            "    mean_KL: 0.002908137394115329\n",
            "    median_KL: 3.931652159394616e-08\n",
            "    model: {}\n",
            "    policy_loss: -25.598838806152344\n",
            "    var_gnorm: 10.2184476852417\n",
            "    vf_explained_var: 0.8239820003509521\n",
            "    vf_loss: 12.227080345153809\n",
            "  learner_queue:\n",
            "    size_count: 70\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 35450\n",
            "  num_steps_trained: 35000\n",
            "  num_weight_syncs: 709\n",
            "  sample_throughput: 310.003\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1457.318\n",
            "    learner_grad_time_ms: 140.48\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 14.198\n",
            "  train_throughput: 286.157\n",
            "iterations_since_restore: 12\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 125.67403674125671\n",
            "time_this_iter_s: 10.47110629081726\n",
            "time_total_s: 125.67403674125671\n",
            "timestamp: 1553483626\n",
            "timesteps_since_restore: 35450\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 35450\n",
            "training_iteration: 12\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-13-56\n",
            "done: false\n",
            "episode_len_mean: 216.57\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.96\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 216\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 418.4557189941406\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.011369867250323296\n",
            "    mean_KL: 0.001223711296916008\n",
            "    median_KL: 1.565861538210811e-07\n",
            "    model: {}\n",
            "    policy_loss: 5.914250373840332\n",
            "    var_gnorm: 10.26406192779541\n",
            "    vf_explained_var: 0.9524537920951843\n",
            "    vf_loss: 2.815359592437744\n",
            "  learner_queue:\n",
            "    size_count: 77\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 38700\n",
            "  num_steps_trained: 38500\n",
            "  num_weight_syncs: 774\n",
            "  sample_throughput: 309.824\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1489.27\n",
            "    learner_grad_time_ms: 138.771\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.492\n",
            "  train_throughput: 333.657\n",
            "iterations_since_restore: 13\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 136.1506998538971\n",
            "time_this_iter_s: 10.47666311264038\n",
            "time_total_s: 136.1506998538971\n",
            "timestamp: 1553483636\n",
            "timesteps_since_restore: 38700\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 38700\n",
            "training_iteration: 13\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-14-07\n",
            "done: false\n",
            "episode_len_mean: 216.37\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.95\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 234\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 498.6273193359375\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.008350932039320469\n",
            "    mean_KL: 0.0009909917134791613\n",
            "    median_KL: 4.09556619729301e-08\n",
            "    model: {}\n",
            "    policy_loss: -20.275875091552734\n",
            "    var_gnorm: 10.306737899780273\n",
            "    vf_explained_var: 0.9127228260040283\n",
            "    vf_loss: 6.604604244232178\n",
            "  learner_queue:\n",
            "    size_count: 84\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 42000\n",
            "  num_steps_trained: 41500\n",
            "  num_weight_syncs: 840\n",
            "  sample_throughput: 312.783\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1453.707\n",
            "    learner_grad_time_ms: 142.264\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 16.855\n",
            "  train_throughput: 284.348\n",
            "iterations_since_restore: 14\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 146.68902564048767\n",
            "time_this_iter_s: 10.538325786590576\n",
            "time_total_s: 146.68902564048767\n",
            "timestamp: 1553483647\n",
            "timesteps_since_restore: 42000\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 42000\n",
            "training_iteration: 14\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-14-17\n",
            "done: false\n",
            "episode_len_mean: 214.33\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.87\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 252\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 577.756591796875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0028136582113802433\n",
            "    mean_KL: 0.00011784499656641856\n",
            "    median_KL: 6.187178769323509e-08\n",
            "    model: {}\n",
            "    policy_loss: -15.21813678741455\n",
            "    var_gnorm: 10.355287551879883\n",
            "    vf_explained_var: 0.9488181471824646\n",
            "    vf_loss: 4.1363325119018555\n",
            "  learner_queue:\n",
            "    size_count: 90\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 45300\n",
            "  num_steps_trained: 45000\n",
            "  num_weight_syncs: 906\n",
            "  sample_throughput: 313.584\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1449.952\n",
            "    learner_grad_time_ms: 141.835\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.4\n",
            "  train_throughput: 332.589\n",
            "iterations_since_restore: 15\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 157.20179176330566\n",
            "time_this_iter_s: 10.512766122817993\n",
            "time_total_s: 157.20179176330566\n",
            "timestamp: 1553483657\n",
            "timesteps_since_restore: 45300\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 45300\n",
            "training_iteration: 15\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-14-28\n",
            "done: false\n",
            "episode_len_mean: 210.19\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.76\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 21\n",
            "episodes_total: 273\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 624.5300903320312\n",
            "    grad_gnorm: 35.49415969848633\n",
            "    max_KL: 0.004670381546020508\n",
            "    mean_KL: 0.000519521243404597\n",
            "    median_KL: 5.5868945025849825e-08\n",
            "    model: {}\n",
            "    policy_loss: -5.421710014343262\n",
            "    var_gnorm: 10.408205032348633\n",
            "    vf_explained_var: 0.9710374474525452\n",
            "    vf_loss: 1.5772444009780884\n",
            "  learner_queue:\n",
            "    size_count: 97\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 48550\n",
            "  num_steps_trained: 48500\n",
            "  num_weight_syncs: 971\n",
            "  sample_throughput: 309.387\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1461.673\n",
            "    learner_grad_time_ms: 140.11\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.059\n",
            "  train_throughput: 333.186\n",
            "iterations_since_restore: 16\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 167.68493843078613\n",
            "time_this_iter_s: 10.483146667480469\n",
            "time_total_s: 167.68493843078613\n",
            "timestamp: 1553483668\n",
            "timesteps_since_restore: 48550\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 48550\n",
            "training_iteration: 16\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-14-38\n",
            "done: false\n",
            "episode_len_mean: 208.67\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.72\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 16\n",
            "episodes_total: 289\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 617.1845703125\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0022691693156957626\n",
            "    mean_KL: 0.00016717262042220682\n",
            "    median_KL: 1.6171824768207443e-07\n",
            "    model: {}\n",
            "    policy_loss: -4.321108818054199\n",
            "    var_gnorm: 10.448637962341309\n",
            "    vf_explained_var: 0.8943329453468323\n",
            "    vf_loss: 5.83846378326416\n",
            "  learner_queue:\n",
            "    size_count: 103\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 51800\n",
            "  num_steps_trained: 51500\n",
            "  num_weight_syncs: 1036\n",
            "  sample_throughput: 312.663\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1467.831\n",
            "    learner_grad_time_ms: 145.425\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.22\n",
            "  train_throughput: 288.612\n",
            "iterations_since_restore: 17\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 178.0673532485962\n",
            "time_this_iter_s: 10.382414817810059\n",
            "time_total_s: 178.0673532485962\n",
            "timestamp: 1553483678\n",
            "timesteps_since_restore: 51800\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 51800\n",
            "training_iteration: 17\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-14-48\n",
            "done: false\n",
            "episode_len_mean: 204.19\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.6\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 21\n",
            "episodes_total: 310\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 622.341064453125\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0011224441695958376\n",
            "    mean_KL: 6.563856732100248e-05\n",
            "    median_KL: 5.924680834823448e-08\n",
            "    model: {}\n",
            "    policy_loss: -16.69586944580078\n",
            "    var_gnorm: 10.502574920654297\n",
            "    vf_explained_var: 0.9756436944007874\n",
            "    vf_loss: 2.2560153007507324\n",
            "  learner_queue:\n",
            "    size_count: 110\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 55050\n",
            "  num_steps_trained: 55000\n",
            "  num_weight_syncs: 1101\n",
            "  sample_throughput: 310.093\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1467.322\n",
            "    learner_grad_time_ms: 138.409\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 26.481\n",
            "  train_throughput: 333.946\n",
            "iterations_since_restore: 18\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 188.53649926185608\n",
            "time_this_iter_s: 10.469146013259888\n",
            "time_total_s: 188.53649926185608\n",
            "timestamp: 1553483688\n",
            "timesteps_since_restore: 55050\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 55050\n",
            "training_iteration: 18\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-14-59\n",
            "done: false\n",
            "episode_len_mean: 199.57\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.48\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 19\n",
            "episodes_total: 329\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 628.2653198242188\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0022109858691692352\n",
            "    mean_KL: 9.212195436703041e-05\n",
            "    median_KL: 1.7705181676319626e-07\n",
            "    model: {}\n",
            "    policy_loss: -9.181194305419922\n",
            "    var_gnorm: 10.546756744384766\n",
            "    vf_explained_var: 0.9152160882949829\n",
            "    vf_loss: 5.159904956817627\n",
            "  learner_queue:\n",
            "    size_count: 116\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 58300\n",
            "  num_steps_trained: 58000\n",
            "  num_weight_syncs: 1166\n",
            "  sample_throughput: 310.028\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1464.709\n",
            "    learner_grad_time_ms: 148.959\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.78\n",
            "  train_throughput: 286.18\n",
            "iterations_since_restore: 19\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 199.00910091400146\n",
            "time_this_iter_s: 10.472601652145386\n",
            "time_total_s: 199.00910091400146\n",
            "timestamp: 1553483699\n",
            "timesteps_since_restore: 58300\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 58300\n",
            "training_iteration: 19\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-15-09\n",
            "done: false\n",
            "episode_len_mean: 193.0\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.32\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 22\n",
            "episodes_total: 351\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 642.5885620117188\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.00017609866335988045\n",
            "    mean_KL: 1.974346196220722e-05\n",
            "    median_KL: 1.452369104981699e-07\n",
            "    model: {}\n",
            "    policy_loss: -9.462441444396973\n",
            "    var_gnorm: 10.5747709274292\n",
            "    vf_explained_var: 0.9437596201896667\n",
            "    vf_loss: 2.7474560737609863\n",
            "  learner_queue:\n",
            "    size_count: 123\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 61500\n",
            "  num_steps_trained: 61000\n",
            "  num_weight_syncs: 1230\n",
            "  sample_throughput: 305.105\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1479.278\n",
            "    learner_grad_time_ms: 148.6\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 16.514\n",
            "  train_throughput: 286.036\n",
            "iterations_since_restore: 20\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 209.48613929748535\n",
            "time_this_iter_s: 10.477038383483887\n",
            "time_total_s: 209.48613929748535\n",
            "timestamp: 1553483709\n",
            "timesteps_since_restore: 61500\n",
            "timesteps_this_iter: 3200\n",
            "timesteps_total: 61500\n",
            "training_iteration: 20\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-15-20\n",
            "done: false\n",
            "episode_len_mean: 192.39\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.28\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 20\n",
            "episodes_total: 371\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 649.6049194335938\n",
            "    grad_gnorm: 15.22883415222168\n",
            "    max_KL: 0.00014104810543358326\n",
            "    mean_KL: 1.1398604328860529e-05\n",
            "    median_KL: 6.338325420074398e-08\n",
            "    model: {}\n",
            "    policy_loss: -4.784745216369629\n",
            "    var_gnorm: 10.605552673339844\n",
            "    vf_explained_var: 0.9815478324890137\n",
            "    vf_loss: 0.5458778738975525\n",
            "  learner_queue:\n",
            "    size_count: 129\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 64750\n",
            "  num_steps_trained: 64500\n",
            "  num_weight_syncs: 1295\n",
            "  sample_throughput: 309.196\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1473.715\n",
            "    learner_grad_time_ms: 148.963\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.263\n",
            "  train_throughput: 332.981\n",
            "iterations_since_restore: 21\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 219.98661828041077\n",
            "time_this_iter_s: 10.500478982925415\n",
            "time_total_s: 219.98661828041077\n",
            "timestamp: 1553483720\n",
            "timesteps_since_restore: 64750\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 64750\n",
            "training_iteration: 21\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-15-30\n",
            "done: false\n",
            "episode_len_mean: 192.44\n",
            "episode_reward_max: 4.0\n",
            "episode_reward_mean: 1.31\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 389\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 650.4983520507812\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.001633504405617714\n",
            "    mean_KL: 7.486423419322819e-05\n",
            "    median_KL: 2.0893797625376465e-07\n",
            "    model: {}\n",
            "    policy_loss: -2.5409109592437744\n",
            "    var_gnorm: 10.64272689819336\n",
            "    vf_explained_var: 0.9546326398849487\n",
            "    vf_loss: 1.6386733055114746\n",
            "  learner_queue:\n",
            "    size_count: 136\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 68000\n",
            "  num_steps_trained: 67500\n",
            "  num_weight_syncs: 1360\n",
            "  sample_throughput: 310.326\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1467.991\n",
            "    learner_grad_time_ms: 146.586\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 14.552\n",
            "  train_throughput: 286.455\n",
            "iterations_since_restore: 22\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 230.44768118858337\n",
            "time_this_iter_s: 10.461062908172607\n",
            "time_total_s: 230.44768118858337\n",
            "timestamp: 1553483730\n",
            "timesteps_since_restore: 68000\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 68000\n",
            "training_iteration: 22\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-15-41\n",
            "done: false\n",
            "episode_len_mean: 188.08\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.18\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 21\n",
            "episodes_total: 410\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 644.7128295898438\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.00022609374718740582\n",
            "    mean_KL: 2.0984120055800304e-05\n",
            "    median_KL: 1.4356487554323394e-07\n",
            "    model: {}\n",
            "    policy_loss: 6.925200462341309\n",
            "    var_gnorm: 10.659700393676758\n",
            "    vf_explained_var: 0.8281981348991394\n",
            "    vf_loss: 11.855887413024902\n",
            "  learner_queue:\n",
            "    size_count: 142\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 71250\n",
            "  num_steps_trained: 71000\n",
            "  num_weight_syncs: 1425\n",
            "  sample_throughput: 309.298\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1477.615\n",
            "    learner_grad_time_ms: 142.705\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 14.915\n",
            "  train_throughput: 333.09\n",
            "iterations_since_restore: 23\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 240.94461846351624\n",
            "time_this_iter_s: 10.496937274932861\n",
            "time_total_s: 240.94461846351624\n",
            "timestamp: 1553483741\n",
            "timesteps_since_restore: 71250\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 71250\n",
            "training_iteration: 23\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-15-51\n",
            "done: false\n",
            "episode_len_mean: 193.28\n",
            "episode_reward_max: 3.0\n",
            "episode_reward_mean: 1.32\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 18\n",
            "episodes_total: 428\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 648.5657958984375\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.001269645057618618\n",
            "    mean_KL: 7.11929242243059e-05\n",
            "    median_KL: 5.6908515233544676e-08\n",
            "    model: {}\n",
            "    policy_loss: 2.2879996299743652\n",
            "    var_gnorm: 10.688746452331543\n",
            "    vf_explained_var: 0.9735554456710815\n",
            "    vf_loss: 1.870976448059082\n",
            "  learner_queue:\n",
            "    size_count: 149\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 74550\n",
            "  num_steps_trained: 74500\n",
            "  num_weight_syncs: 1491\n",
            "  sample_throughput: 312.909\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1446.096\n",
            "    learner_grad_time_ms: 146.136\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.572\n",
            "  train_throughput: 331.873\n",
            "iterations_since_restore: 24\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 251.47947645187378\n",
            "time_this_iter_s: 10.534857988357544\n",
            "time_total_s: 251.47947645187378\n",
            "timestamp: 1553483751\n",
            "timesteps_since_restore: 74550\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 74550\n",
            "training_iteration: 24\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-16-02\n",
            "done: false\n",
            "episode_len_mean: 198.67\n",
            "episode_reward_max: 6.0\n",
            "episode_reward_mean: 1.48\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 17\n",
            "episodes_total: 445\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 628.0889282226562\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.010597225278615952\n",
            "    mean_KL: 0.0006747847073711455\n",
            "    median_KL: 4.943616715991084e-08\n",
            "    model: {}\n",
            "    policy_loss: -60.6129264831543\n",
            "    var_gnorm: 10.728891372680664\n",
            "    vf_explained_var: 0.7592094540596008\n",
            "    vf_loss: 20.799232482910156\n",
            "  learner_queue:\n",
            "    size_count: 155\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 77800\n",
            "  num_steps_trained: 77500\n",
            "  num_weight_syncs: 1556\n",
            "  sample_throughput: 311.109\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1458.013\n",
            "    learner_grad_time_ms: 157.195\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.172\n",
            "  train_throughput: 287.178\n",
            "iterations_since_restore: 25\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 261.91467356681824\n",
            "time_this_iter_s: 10.435197114944458\n",
            "time_total_s: 261.91467356681824\n",
            "timestamp: 1553483762\n",
            "timesteps_since_restore: 77800\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 77800\n",
            "training_iteration: 25\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-16-12\n",
            "done: false\n",
            "episode_len_mean: 211.82\n",
            "episode_reward_max: 8.0\n",
            "episode_reward_mean: 1.94\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 11\n",
            "episodes_total: 456\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 584.60498046875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0032697245478630066\n",
            "    mean_KL: 0.00028099576593376696\n",
            "    median_KL: 5.745831543890745e-08\n",
            "    model: {}\n",
            "    policy_loss: -53.67474365234375\n",
            "    var_gnorm: 10.790278434753418\n",
            "    vf_explained_var: 0.1962757706642151\n",
            "    vf_loss: 48.99433517456055\n",
            "  learner_queue:\n",
            "    size_count: 162\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 81100\n",
            "  num_steps_trained: 81000\n",
            "  num_weight_syncs: 1622\n",
            "  sample_throughput: 316.574\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1433.12\n",
            "    learner_grad_time_ms: 147.325\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.305\n",
            "  train_throughput: 335.76\n",
            "iterations_since_restore: 26\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 272.3276484012604\n",
            "time_this_iter_s: 10.412974834442139\n",
            "time_total_s: 272.3276484012604\n",
            "timestamp: 1553483772\n",
            "timesteps_since_restore: 81100\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 81100\n",
            "training_iteration: 26\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-16-23\n",
            "done: false\n",
            "episode_len_mean: 228.46\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 2.65\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 12\n",
            "episodes_total: 468\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 567.0618286132812\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0014821439981460571\n",
            "    mean_KL: 0.00013182059046812356\n",
            "    median_KL: 4.9295724835474175e-08\n",
            "    model: {}\n",
            "    policy_loss: 58.79781723022461\n",
            "    var_gnorm: 10.868907928466797\n",
            "    vf_explained_var: 0.41285544633865356\n",
            "    vf_loss: 47.57744216918945\n",
            "  learner_queue:\n",
            "    size_count: 169\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 84500\n",
            "  num_steps_trained: 84000\n",
            "  num_weight_syncs: 1690\n",
            "  sample_throughput: 321.972\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1414.951\n",
            "    learner_grad_time_ms: 143.605\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 19.186\n",
            "  train_throughput: 284.093\n",
            "iterations_since_restore: 27\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 282.87460708618164\n",
            "time_this_iter_s: 10.546958684921265\n",
            "time_total_s: 282.87460708618164\n",
            "timestamp: 1553483783\n",
            "timesteps_since_restore: 84500\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 84500\n",
            "training_iteration: 27\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-16-33\n",
            "done: false\n",
            "episode_len_mean: 242.58\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 3.24\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 478\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 559.0974731445312\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0005436604842543602\n",
            "    mean_KL: 4.323910616221838e-05\n",
            "    median_KL: 5.394406343839364e-08\n",
            "    model: {}\n",
            "    policy_loss: -54.47679901123047\n",
            "    var_gnorm: 10.938273429870605\n",
            "    vf_explained_var: 0.4929298162460327\n",
            "    vf_loss: 40.8902587890625\n",
            "  learner_queue:\n",
            "    size_count: 175\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 87800\n",
            "  num_steps_trained: 87500\n",
            "  num_weight_syncs: 1756\n",
            "  sample_throughput: 319.116\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1414.436\n",
            "    learner_grad_time_ms: 144.941\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.251\n",
            "  train_throughput: 338.457\n",
            "iterations_since_restore: 28\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 293.2035219669342\n",
            "time_this_iter_s: 10.328914880752563\n",
            "time_total_s: 293.2035219669342\n",
            "timestamp: 1553483793\n",
            "timesteps_since_restore: 87800\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 87800\n",
            "training_iteration: 28\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-16-44\n",
            "done: false\n",
            "episode_len_mean: 256.48\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 3.93\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 491\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 585.6255493164062\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0030683130025863647\n",
            "    mean_KL: 0.00018912975792773068\n",
            "    median_KL: 5.2804459471644805e-08\n",
            "    model: {}\n",
            "    policy_loss: -19.595949172973633\n",
            "    var_gnorm: 11.000563621520996\n",
            "    vf_explained_var: 0.40813368558883667\n",
            "    vf_loss: 25.572561264038086\n",
            "  learner_queue:\n",
            "    size_count: 182\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 91100\n",
            "  num_steps_trained: 91000\n",
            "  num_weight_syncs: 1822\n",
            "  sample_throughput: 316.625\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1434.081\n",
            "    learner_grad_time_ms: 144.069\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.019\n",
            "  train_throughput: 335.814\n",
            "iterations_since_restore: 29\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 303.6145179271698\n",
            "time_this_iter_s: 10.410995960235596\n",
            "time_total_s: 303.6145179271698\n",
            "timestamp: 1553483804\n",
            "timesteps_since_restore: 91100\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 91100\n",
            "training_iteration: 29\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-16-54\n",
            "done: false\n",
            "episode_len_mean: 270.02\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 4.51\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 12\n",
            "episodes_total: 503\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 614.6731567382812\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0031343884766101837\n",
            "    mean_KL: 0.00018034873937722296\n",
            "    median_KL: 6.077724634678816e-08\n",
            "    model: {}\n",
            "    policy_loss: 29.61726951599121\n",
            "    var_gnorm: 11.041119575500488\n",
            "    vf_explained_var: 0.4484233856201172\n",
            "    vf_loss: 22.93660545349121\n",
            "  learner_queue:\n",
            "    size_count: 188\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 94400\n",
            "  num_steps_trained: 94000\n",
            "  num_weight_syncs: 1888\n",
            "  sample_throughput: 319.749\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1432.684\n",
            "    learner_grad_time_ms: 140.615\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 10.974\n",
            "  train_throughput: 290.681\n",
            "iterations_since_restore: 30\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 313.9226005077362\n",
            "time_this_iter_s: 10.308082580566406\n",
            "time_total_s: 313.9226005077362\n",
            "timestamp: 1553483814\n",
            "timesteps_since_restore: 94400\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 94400\n",
            "training_iteration: 30\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-17-04\n",
            "done: false\n",
            "episode_len_mean: 281.22\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 5.09\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 516\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 603.3204956054688\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.0014219973236322403\n",
            "    mean_KL: 0.0001367859513266012\n",
            "    median_KL: 1.5392078012155253e-07\n",
            "    model: {}\n",
            "    policy_loss: -74.978515625\n",
            "    var_gnorm: 11.105008125305176\n",
            "    vf_explained_var: 0.6628899574279785\n",
            "    vf_loss: 23.696916580200195\n",
            "  learner_queue:\n",
            "    size_count: 195\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 97650\n",
            "  num_steps_trained: 97500\n",
            "  num_weight_syncs: 1953\n",
            "  sample_throughput: 312.2\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1443.655\n",
            "    learner_grad_time_ms: 141.915\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.522\n",
            "  train_throughput: 336.216\n",
            "iterations_since_restore: 31\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 324.32081055641174\n",
            "time_this_iter_s: 10.398210048675537\n",
            "time_total_s: 324.32081055641174\n",
            "timestamp: 1553483824\n",
            "timesteps_since_restore: 97650\n",
            "timesteps_this_iter: 3250\n",
            "timesteps_total: 97650\n",
            "training_iteration: 31\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-17-15\n",
            "done: false\n",
            "episode_len_mean: 289.16\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 5.71\n",
            "episode_reward_min: 0.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 529\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 587.523193359375\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.0011024624109268188\n",
            "    mean_KL: 7.917724724393338e-05\n",
            "    median_KL: 1.4419904914575454e-07\n",
            "    model: {}\n",
            "    policy_loss: 45.21921157836914\n",
            "    var_gnorm: 11.152630805969238\n",
            "    vf_explained_var: 0.7838276028633118\n",
            "    vf_loss: 12.21929931640625\n",
            "  learner_queue:\n",
            "    size_count: 201\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 100950\n",
            "  num_steps_trained: 100500\n",
            "  num_weight_syncs: 2019\n",
            "  sample_throughput: 318.211\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1457.502\n",
            "    learner_grad_time_ms: 144.618\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.222\n",
            "  train_throughput: 289.283\n",
            "iterations_since_restore: 32\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 334.68063020706177\n",
            "time_this_iter_s: 10.359819650650024\n",
            "time_total_s: 334.68063020706177\n",
            "timestamp: 1553483835\n",
            "timesteps_since_restore: 100950\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 100950\n",
            "training_iteration: 32\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-17-25\n",
            "done: false\n",
            "episode_len_mean: 297.76\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.32\n",
            "episode_reward_min: 1.0\n",
            "episodes_this_iter: 14\n",
            "episodes_total: 543\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 586.787109375\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.001123504713177681\n",
            "    mean_KL: 6.518950976897031e-05\n",
            "    median_KL: 6.392234297436516e-08\n",
            "    model: {}\n",
            "    policy_loss: 9.879831314086914\n",
            "    var_gnorm: 11.200601577758789\n",
            "    vf_explained_var: 0.856438398361206\n",
            "    vf_loss: 6.688604831695557\n",
            "  learner_queue:\n",
            "    size_count: 208\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 104250\n",
            "  num_steps_trained: 104000\n",
            "  num_weight_syncs: 2085\n",
            "  sample_throughput: 314.812\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1416.421\n",
            "    learner_grad_time_ms: 152.332\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.189\n",
            "  train_throughput: 333.892\n",
            "iterations_since_restore: 33\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 345.15007734298706\n",
            "time_this_iter_s: 10.469447135925293\n",
            "time_total_s: 345.15007734298706\n",
            "timestamp: 1553483845\n",
            "timesteps_since_restore: 104250\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 104250\n",
            "training_iteration: 33\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-17-36\n",
            "done: false\n",
            "episode_len_mean: 297.06\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.76\n",
            "episode_reward_min: 1.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 556\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 596.6710815429688\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.004146959632635117\n",
            "    mean_KL: 0.0001267720654141158\n",
            "    median_KL: 1.6641814681861433e-07\n",
            "    model: {}\n",
            "    policy_loss: 69.90547943115234\n",
            "    var_gnorm: 11.249024391174316\n",
            "    vf_explained_var: 0.542717695236206\n",
            "    vf_loss: 36.46860122680664\n",
            "  learner_queue:\n",
            "    size_count: 215\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 107550\n",
            "  num_steps_trained: 107000\n",
            "  num_weight_syncs: 2151\n",
            "  sample_throughput: 314.105\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1447.472\n",
            "    learner_grad_time_ms: 143.882\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 20.662\n",
            "  train_throughput: 285.55\n",
            "iterations_since_restore: 34\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 355.6439685821533\n",
            "time_this_iter_s: 10.49389123916626\n",
            "time_total_s: 355.6439685821533\n",
            "timestamp: 1553483856\n",
            "timesteps_since_restore: 107550\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 107550\n",
            "training_iteration: 34\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-17-46\n",
            "done: false\n",
            "episode_len_mean: 290.17\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 6.79\n",
            "episode_reward_min: 1.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 569\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 621.8634643554688\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0021039890125393867\n",
            "    mean_KL: 0.00012066592898918316\n",
            "    median_KL: 5.047439799454878e-08\n",
            "    model: {}\n",
            "    policy_loss: 13.73448371887207\n",
            "    var_gnorm: 11.281432151794434\n",
            "    vf_explained_var: 0.643599808216095\n",
            "    vf_loss: 16.47496223449707\n",
            "  learner_queue:\n",
            "    size_count: 221\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 110900\n",
            "  num_steps_trained: 110500\n",
            "  num_weight_syncs: 2218\n",
            "  sample_throughput: 317.942\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1432.679\n",
            "    learner_grad_time_ms: 148.188\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 12.977\n",
            "  train_throughput: 332.178\n",
            "iterations_since_restore: 35\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 366.16846799850464\n",
            "time_this_iter_s: 10.524499416351318\n",
            "time_total_s: 366.16846799850464\n",
            "timestamp: 1553483866\n",
            "timesteps_since_restore: 110900\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 110900\n",
            "training_iteration: 35\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-17-57\n",
            "done: false\n",
            "episode_len_mean: 285.92\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 6.66\n",
            "episode_reward_min: 1.0\n",
            "episodes_this_iter: 11\n",
            "episodes_total: 580\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 617.8666381835938\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0011789016425609589\n",
            "    mean_KL: 9.514462726656348e-05\n",
            "    median_KL: 5.3320768245157524e-08\n",
            "    model: {}\n",
            "    policy_loss: 112.7285385131836\n",
            "    var_gnorm: 11.326583862304688\n",
            "    vf_explained_var: 0.22302359342575073\n",
            "    vf_loss: 62.072975158691406\n",
            "  learner_queue:\n",
            "    size_count: 228\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 114200\n",
            "  num_steps_trained: 114000\n",
            "  num_weight_syncs: 2284\n",
            "  sample_throughput: 317.071\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1423.032\n",
            "    learner_grad_time_ms: 146.562\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.23\n",
            "  train_throughput: 336.287\n",
            "iterations_since_restore: 36\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 376.56342816352844\n",
            "time_this_iter_s: 10.394960165023804\n",
            "time_total_s: 376.56342816352844\n",
            "timestamp: 1553483877\n",
            "timesteps_since_restore: 114200\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 114200\n",
            "training_iteration: 36\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-18-07\n",
            "done: false\n",
            "episode_len_mean: 284.13\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 6.41\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 14\n",
            "episodes_total: 594\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 595.3250732421875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0009996439330279827\n",
            "    mean_KL: 5.398123903432861e-05\n",
            "    median_KL: 5.8106792266698903e-08\n",
            "    model: {}\n",
            "    policy_loss: -59.8925895690918\n",
            "    var_gnorm: 11.390531539916992\n",
            "    vf_explained_var: 0.7340312004089355\n",
            "    vf_loss: 17.24118423461914\n",
            "  learner_queue:\n",
            "    size_count: 235\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 117500\n",
            "  num_steps_trained: 117000\n",
            "  num_weight_syncs: 2350\n",
            "  sample_throughput: 314.487\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1433.867\n",
            "    learner_grad_time_ms: 145.891\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 18.39\n",
            "  train_throughput: 285.897\n",
            "iterations_since_restore: 37\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 387.0433187484741\n",
            "time_this_iter_s: 10.479890584945679\n",
            "time_total_s: 387.0433187484741\n",
            "timestamp: 1553483887\n",
            "timesteps_since_restore: 117500\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 117500\n",
            "training_iteration: 37\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-18-18\n",
            "done: false\n",
            "episode_len_mean: 284.37\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 6.38\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 12\n",
            "episodes_total: 606\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 610.5940551757812\n",
            "    grad_gnorm: 40.00000762939453\n",
            "    max_KL: 0.009548045694828033\n",
            "    mean_KL: 0.0005195608246140182\n",
            "    median_KL: 6.283126907646874e-08\n",
            "    model: {}\n",
            "    policy_loss: 100.93396759033203\n",
            "    var_gnorm: 11.44792366027832\n",
            "    vf_explained_var: 0.4698687791824341\n",
            "    vf_loss: 38.53649139404297\n",
            "  learner_queue:\n",
            "    size_count: 241\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 120850\n",
            "  num_steps_trained: 120500\n",
            "  num_weight_syncs: 2417\n",
            "  sample_throughput: 320.176\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1429.176\n",
            "    learner_grad_time_ms: 147.005\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.472\n",
            "  train_throughput: 334.512\n",
            "iterations_since_restore: 38\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 397.49431824684143\n",
            "time_this_iter_s: 10.45099949836731\n",
            "time_total_s: 397.49431824684143\n",
            "timestamp: 1553483898\n",
            "timesteps_since_restore: 120850\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 120850\n",
            "training_iteration: 38\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-18-28\n",
            "done: false\n",
            "episode_len_mean: 289.54\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 6.47\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 619\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 592.0591430664062\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0023195911198854446\n",
            "    mean_KL: 0.00010790603118948638\n",
            "    median_KL: 1.3627720818476519e-07\n",
            "    model: {}\n",
            "    policy_loss: -48.6977424621582\n",
            "    var_gnorm: 11.513147354125977\n",
            "    vf_explained_var: 0.7044954299926758\n",
            "    vf_loss: 16.180158615112305\n",
            "  learner_queue:\n",
            "    size_count: 248\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 124200\n",
            "  num_steps_trained: 124000\n",
            "  num_weight_syncs: 2484\n",
            "  sample_throughput: 318.995\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1429.069\n",
            "    learner_grad_time_ms: 144.692\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.237\n",
            "  train_throughput: 333.279\n",
            "iterations_since_restore: 39\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 407.98360776901245\n",
            "time_this_iter_s: 10.48928952217102\n",
            "time_total_s: 407.98360776901245\n",
            "timestamp: 1553483908\n",
            "timesteps_since_restore: 124200\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 124200\n",
            "training_iteration: 39\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-18-39\n",
            "done: false\n",
            "episode_len_mean: 297.71\n",
            "episode_reward_max: 12.0\n",
            "episode_reward_mean: 6.68\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 629\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 579.132080078125\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0017176112160086632\n",
            "    mean_KL: 8.785419777268544e-05\n",
            "    median_KL: 1.4007086690526194e-07\n",
            "    model: {}\n",
            "    policy_loss: -2.4312500953674316\n",
            "    var_gnorm: 11.576138496398926\n",
            "    vf_explained_var: 0.6510416269302368\n",
            "    vf_loss: 20.04106903076172\n",
            "  learner_queue:\n",
            "    size_count: 255\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 127550\n",
            "  num_steps_trained: 127500\n",
            "  num_weight_syncs: 2551\n",
            "  sample_throughput: 320.282\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1409.873\n",
            "    learner_grad_time_ms: 143.834\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 12.997\n",
            "  train_throughput: 334.623\n",
            "iterations_since_restore: 40\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 418.42985558509827\n",
            "time_this_iter_s: 10.446247816085815\n",
            "time_total_s: 418.42985558509827\n",
            "timestamp: 1553483919\n",
            "timesteps_since_restore: 127550\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 127550\n",
            "training_iteration: 40\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-18-49\n",
            "done: false\n",
            "episode_len_mean: 304.28\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.85\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 9\n",
            "episodes_total: 638\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 564.77197265625\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0007887538522481918\n",
            "    mean_KL: 4.616636215359904e-05\n",
            "    median_KL: 4.880492809888892e-08\n",
            "    model: {}\n",
            "    policy_loss: -56.74076843261719\n",
            "    var_gnorm: 11.631913185119629\n",
            "    vf_explained_var: 0.867135763168335\n",
            "    vf_loss: 11.24235725402832\n",
            "  learner_queue:\n",
            "    size_count: 261\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 130900\n",
            "  num_steps_trained: 130500\n",
            "  num_weight_syncs: 2618\n",
            "  sample_throughput: 323.694\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1414.198\n",
            "    learner_grad_time_ms: 144.574\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.162\n",
            "  train_throughput: 289.875\n",
            "iterations_since_restore: 41\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 428.76832008361816\n",
            "time_this_iter_s: 10.338464498519897\n",
            "time_total_s: 428.76832008361816\n",
            "timestamp: 1553483929\n",
            "timesteps_since_restore: 130900\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 130900\n",
            "training_iteration: 41\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-19-00\n",
            "done: false\n",
            "episode_len_mean: 312.79\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.77\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 11\n",
            "episodes_total: 649\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 579.1248779296875\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.0019176620990037918\n",
            "    mean_KL: 7.32422195142135e-05\n",
            "    median_KL: 1.5903191297184094e-07\n",
            "    model: {}\n",
            "    policy_loss: -75.25210571289062\n",
            "    var_gnorm: 11.697416305541992\n",
            "    vf_explained_var: 0.6783318519592285\n",
            "    vf_loss: 25.797422409057617\n",
            "  learner_queue:\n",
            "    size_count: 268\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 134250\n",
            "  num_steps_trained: 134000\n",
            "  num_weight_syncs: 2685\n",
            "  sample_throughput: 316.01\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1427.556\n",
            "    learner_grad_time_ms: 146.987\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 14.855\n",
            "  train_throughput: 330.159\n",
            "iterations_since_restore: 42\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 439.35894680023193\n",
            "time_this_iter_s: 10.59062671661377\n",
            "time_total_s: 439.35894680023193\n",
            "timestamp: 1553483940\n",
            "timesteps_since_restore: 134250\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 134250\n",
            "training_iteration: 42\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-19-10\n",
            "done: false\n",
            "episode_len_mean: 314.91\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.62\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 12\n",
            "episodes_total: 661\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 603.1753540039062\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.002117043361067772\n",
            "    mean_KL: 0.00011864525004057214\n",
            "    median_KL: 2.0190051941426645e-07\n",
            "    model: {}\n",
            "    policy_loss: 52.539127349853516\n",
            "    var_gnorm: 11.761103630065918\n",
            "    vf_explained_var: 0.5166886448860168\n",
            "    vf_loss: 30.526782989501953\n",
            "  learner_queue:\n",
            "    size_count: 275\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 137600\n",
            "  num_steps_trained: 137500\n",
            "  num_weight_syncs: 2752\n",
            "  sample_throughput: 318.261\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1427.02\n",
            "    learner_grad_time_ms: 147.048\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.578\n",
            "  train_throughput: 332.511\n",
            "iterations_since_restore: 43\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 449.8725492954254\n",
            "time_this_iter_s: 10.513602495193481\n",
            "time_total_s: 449.8725492954254\n",
            "timestamp: 1553483950\n",
            "timesteps_since_restore: 137600\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 137600\n",
            "training_iteration: 43\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-19-21\n",
            "done: false\n",
            "episode_len_mean: 317.14\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.74\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 13\n",
            "episodes_total: 674\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 587.4581909179688\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.0018774955533444881\n",
            "    mean_KL: 5.4947064199950546e-05\n",
            "    median_KL: 5.881166487142764e-08\n",
            "    model: {}\n",
            "    policy_loss: 41.29307174682617\n",
            "    var_gnorm: 11.818233489990234\n",
            "    vf_explained_var: 0.2345837950706482\n",
            "    vf_loss: 53.64647674560547\n",
            "  learner_queue:\n",
            "    size_count: 281\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 140950\n",
            "  num_steps_trained: 140500\n",
            "  num_weight_syncs: 2819\n",
            "  sample_throughput: 320.957\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1408.851\n",
            "    learner_grad_time_ms: 144.499\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.393\n",
            "  train_throughput: 287.424\n",
            "iterations_since_restore: 44\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 460.2991907596588\n",
            "time_this_iter_s: 10.426641464233398\n",
            "time_total_s: 460.2991907596588\n",
            "timestamp: 1553483961\n",
            "timesteps_since_restore: 140950\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 140950\n",
            "training_iteration: 44\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-19-31\n",
            "done: false\n",
            "episode_len_mean: 320.76\n",
            "episode_reward_max: 14.0\n",
            "episode_reward_mean: 6.97\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 684\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 589.68212890625\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.0011099986732006073\n",
            "    mean_KL: 3.54805015376769e-05\n",
            "    median_KL: 5.9417512687787166e-08\n",
            "    model: {}\n",
            "    policy_loss: -6.431182861328125\n",
            "    var_gnorm: 11.888686180114746\n",
            "    vf_explained_var: 0.5439790487289429\n",
            "    vf_loss: 31.540462493896484\n",
            "  learner_queue:\n",
            "    size_count: 288\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 144300\n",
            "  num_steps_trained: 144000\n",
            "  num_weight_syncs: 2886\n",
            "  sample_throughput: 320.076\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1431.698\n",
            "    learner_grad_time_ms: 140.153\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.359\n",
            "  train_throughput: 334.408\n",
            "iterations_since_restore: 45\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 470.7535951137543\n",
            "time_this_iter_s: 10.454404354095459\n",
            "time_total_s: 470.7535951137543\n",
            "timestamp: 1553483971\n",
            "timesteps_since_restore: 144300\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 144300\n",
            "training_iteration: 45\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-19-41\n",
            "done: false\n",
            "episode_len_mean: 326.15\n",
            "episode_reward_max: 18.0\n",
            "episode_reward_mean: 7.47\n",
            "episode_reward_min: 2.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 694\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 576.3527221679688\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0008412548340857029\n",
            "    mean_KL: 3.783411011681892e-05\n",
            "    median_KL: 5.077457387869799e-08\n",
            "    model: {}\n",
            "    policy_loss: -5.927610874176025\n",
            "    var_gnorm: 11.951478958129883\n",
            "    vf_explained_var: 0.33881717920303345\n",
            "    vf_loss: 47.29936218261719\n",
            "  learner_queue:\n",
            "    size_count: 295\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 147600\n",
            "  num_steps_trained: 147500\n",
            "  num_weight_syncs: 2952\n",
            "  sample_throughput: 318.186\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1417.382\n",
            "    learner_grad_time_ms: 143.545\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.734\n",
            "  train_throughput: 337.47\n",
            "iterations_since_restore: 46\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 481.11324977874756\n",
            "time_this_iter_s: 10.359654664993286\n",
            "time_total_s: 481.11324977874756\n",
            "timestamp: 1553483981\n",
            "timesteps_since_restore: 147600\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 147600\n",
            "training_iteration: 46\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-19-52\n",
            "done: false\n",
            "episode_len_mean: 333.5\n",
            "episode_reward_max: 20.0\n",
            "episode_reward_mean: 7.97\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 704\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 591.0347290039062\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0010933801531791687\n",
            "    mean_KL: 5.987064650980756e-05\n",
            "    median_KL: 5.934832003617885e-08\n",
            "    model: {}\n",
            "    policy_loss: 95.27863311767578\n",
            "    var_gnorm: 12.006062507629395\n",
            "    vf_explained_var: 0.3864888548851013\n",
            "    vf_loss: 39.33462905883789\n",
            "  learner_queue:\n",
            "    size_count: 301\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 150950\n",
            "  num_steps_trained: 150500\n",
            "  num_weight_syncs: 3019\n",
            "  sample_throughput: 322.643\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1409.081\n",
            "    learner_grad_time_ms: 148.443\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.398\n",
            "  train_throughput: 288.934\n",
            "iterations_since_restore: 47\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 491.48503828048706\n",
            "time_this_iter_s: 10.371788501739502\n",
            "time_total_s: 491.48503828048706\n",
            "timestamp: 1553483992\n",
            "timesteps_since_restore: 150950\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 150950\n",
            "training_iteration: 47\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-20-02\n",
            "done: false\n",
            "episode_len_mean: 336.68\n",
            "episode_reward_max: 20.0\n",
            "episode_reward_mean: 8.09\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 11\n",
            "episodes_total: 715\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 576.43408203125\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0014138338156044483\n",
            "    mean_KL: 7.514349999837577e-05\n",
            "    median_KL: 5.2423065000084534e-08\n",
            "    model: {}\n",
            "    policy_loss: -3.1038219928741455\n",
            "    var_gnorm: 12.069913864135742\n",
            "    vf_explained_var: 0.5474731922149658\n",
            "    vf_loss: 34.053131103515625\n",
            "  learner_queue:\n",
            "    size_count: 308\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 154300\n",
            "  num_steps_trained: 154000\n",
            "  num_weight_syncs: 3086\n",
            "  sample_throughput: 320.691\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1412.572\n",
            "    learner_grad_time_ms: 145.894\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.853\n",
            "  train_throughput: 335.05\n",
            "iterations_since_restore: 48\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 501.9191701412201\n",
            "time_this_iter_s: 10.434131860733032\n",
            "time_total_s: 501.9191701412201\n",
            "timestamp: 1553484002\n",
            "timesteps_since_restore: 154300\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 154300\n",
            "training_iteration: 48\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-20-13\n",
            "done: false\n",
            "episode_len_mean: 340.75\n",
            "episode_reward_max: 20.0\n",
            "episode_reward_mean: 8.19\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 725\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 536.9645385742188\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.0013836007565259933\n",
            "    mean_KL: 9.45899955695495e-05\n",
            "    median_KL: 5.2149360385556065e-08\n",
            "    model: {}\n",
            "    policy_loss: -67.64830780029297\n",
            "    var_gnorm: 12.141363143920898\n",
            "    vf_explained_var: 0.5599342584609985\n",
            "    vf_loss: 32.263328552246094\n",
            "  learner_queue:\n",
            "    size_count: 315\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 157600\n",
            "  num_steps_trained: 157500\n",
            "  num_weight_syncs: 3152\n",
            "  sample_throughput: 319.118\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1406.111\n",
            "    learner_grad_time_ms: 146.77\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.303\n",
            "  train_throughput: 338.459\n",
            "iterations_since_restore: 49\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 512.2492229938507\n",
            "time_this_iter_s: 10.330052852630615\n",
            "time_total_s: 512.2492229938507\n",
            "timestamp: 1553484013\n",
            "timesteps_since_restore: 157600\n",
            "timesteps_this_iter: 3300\n",
            "timesteps_total: 157600\n",
            "training_iteration: 49\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-20-23\n",
            "done: false\n",
            "episode_len_mean: 338.44\n",
            "episode_reward_max: 20.0\n",
            "episode_reward_mean: 8.23\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 11\n",
            "episodes_total: 736\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 532.7351684570312\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0006005908362567425\n",
            "    mean_KL: 4.3179665226489305e-05\n",
            "    median_KL: 3.800480286031416e-08\n",
            "    model: {}\n",
            "    policy_loss: -13.785711288452148\n",
            "    var_gnorm: 12.208870887756348\n",
            "    vf_explained_var: 0.7422103881835938\n",
            "    vf_loss: 14.974407196044922\n",
            "  learner_queue:\n",
            "    size_count: 322\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 161000\n",
            "  num_steps_trained: 160500\n",
            "  num_weight_syncs: 3220\n",
            "  sample_throughput: 322.733\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1414.382\n",
            "    learner_grad_time_ms: 141.306\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 18.88\n",
            "  train_throughput: 284.765\n",
            "iterations_since_restore: 50\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 522.7713255882263\n",
            "time_this_iter_s: 10.52210259437561\n",
            "time_total_s: 522.7713255882263\n",
            "timestamp: 1553484023\n",
            "timesteps_since_restore: 161000\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 161000\n",
            "training_iteration: 50\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-20-34\n",
            "done: false\n",
            "episode_len_mean: 340.3\n",
            "episode_reward_max: 20.0\n",
            "episode_reward_mean: 8.37\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 746\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 545.9437255859375\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0009422702714800835\n",
            "    mean_KL: 5.716519444831647e-05\n",
            "    median_KL: 5.461219387825622e-08\n",
            "    model: {}\n",
            "    policy_loss: 52.89999008178711\n",
            "    var_gnorm: 12.269777297973633\n",
            "    vf_explained_var: 0.538673996925354\n",
            "    vf_loss: 34.645565032958984\n",
            "  learner_queue:\n",
            "    size_count: 328\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 164350\n",
            "  num_steps_trained: 164000\n",
            "  num_weight_syncs: 3287\n",
            "  sample_throughput: 320.543\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1424.101\n",
            "    learner_grad_time_ms: 139.389\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.359\n",
            "  train_throughput: 334.896\n",
            "iterations_since_restore: 51\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 533.2101304531097\n",
            "time_this_iter_s: 10.438804864883423\n",
            "time_total_s: 533.2101304531097\n",
            "timestamp: 1553484034\n",
            "timesteps_since_restore: 164350\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 164350\n",
            "training_iteration: 51\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-20-44\n",
            "done: false\n",
            "episode_len_mean: 341.72\n",
            "episode_reward_max: 20.0\n",
            "episode_reward_mean: 8.65\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 756\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 545.7994995117188\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0005888300947844982\n",
            "    mean_KL: 3.83033329853788e-05\n",
            "    median_KL: 5.18755207679078e-08\n",
            "    model: {}\n",
            "    policy_loss: -7.700122356414795\n",
            "    var_gnorm: 12.339669227600098\n",
            "    vf_explained_var: 0.6525697708129883\n",
            "    vf_loss: 25.52132225036621\n",
            "  learner_queue:\n",
            "    size_count: 335\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 167700\n",
            "  num_steps_trained: 167500\n",
            "  num_weight_syncs: 3354\n",
            "  sample_throughput: 320.559\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1426.865\n",
            "    learner_grad_time_ms: 139.645\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.131\n",
            "  train_throughput: 334.912\n",
            "iterations_since_restore: 52\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 543.6498310565948\n",
            "time_this_iter_s: 10.439700603485107\n",
            "time_total_s: 543.6498310565948\n",
            "timestamp: 1553484044\n",
            "timesteps_since_restore: 167700\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 167700\n",
            "training_iteration: 52\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-20-54\n",
            "done: false\n",
            "episode_len_mean: 349.02\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 9.03\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 766\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 516.41845703125\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0029750950634479523\n",
            "    mean_KL: 0.00013925519306212664\n",
            "    median_KL: 5.678831271893614e-08\n",
            "    model: {}\n",
            "    policy_loss: -20.204355239868164\n",
            "    var_gnorm: 12.40113639831543\n",
            "    vf_explained_var: 0.5801078081130981\n",
            "    vf_loss: 36.379878997802734\n",
            "  learner_queue:\n",
            "    size_count: 342\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 171100\n",
            "  num_steps_trained: 171000\n",
            "  num_weight_syncs: 3422\n",
            "  sample_throughput: 323.593\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1406.417\n",
            "    learner_grad_time_ms: 140.894\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 14.571\n",
            "  train_throughput: 333.111\n",
            "iterations_since_restore: 53\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 554.1462936401367\n",
            "time_this_iter_s: 10.49646258354187\n",
            "time_total_s: 554.1462936401367\n",
            "timestamp: 1553484054\n",
            "timesteps_since_restore: 171100\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 171100\n",
            "training_iteration: 53\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-21-05\n",
            "done: false\n",
            "episode_len_mean: 359.98\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 9.43\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 774\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 525.9490356445312\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.001116117462515831\n",
            "    mean_KL: 9.126633813139051e-05\n",
            "    median_KL: 5.697075522448358e-08\n",
            "    model: {}\n",
            "    policy_loss: 20.44975471496582\n",
            "    var_gnorm: 12.460789680480957\n",
            "    vf_explained_var: 0.4817408323287964\n",
            "    vf_loss: 37.75989532470703\n",
            "  learner_queue:\n",
            "    size_count: 349\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 174500\n",
            "  num_steps_trained: 174000\n",
            "  num_weight_syncs: 3490\n",
            "  sample_throughput: 324.228\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1393.909\n",
            "    learner_grad_time_ms: 144.216\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.417\n",
            "  train_throughput: 286.084\n",
            "iterations_since_restore: 54\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 564.620765209198\n",
            "time_this_iter_s: 10.47447156906128\n",
            "time_total_s: 564.620765209198\n",
            "timestamp: 1553484065\n",
            "timesteps_since_restore: 174500\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 174500\n",
            "training_iteration: 54\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-21-15\n",
            "done: false\n",
            "episode_len_mean: 365.08\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 9.61\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 9\n",
            "episodes_total: 783\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 552.5382690429688\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0031341426074504852\n",
            "    mean_KL: 7.572374306619167e-05\n",
            "    median_KL: 5.551237691747701e-08\n",
            "    model: {}\n",
            "    policy_loss: 83.1747817993164\n",
            "    var_gnorm: 12.510899543762207\n",
            "    vf_explained_var: 0.4148462414741516\n",
            "    vf_loss: 43.214874267578125\n",
            "  learner_queue:\n",
            "    size_count: 355\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 177700\n",
            "  num_steps_trained: 177500\n",
            "  num_weight_syncs: 3554\n",
            "  sample_throughput: 307.077\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1426.118\n",
            "    learner_grad_time_ms: 167.439\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.092\n",
            "  train_throughput: 335.866\n",
            "iterations_since_restore: 55\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 575.0308880805969\n",
            "time_this_iter_s: 10.410122871398926\n",
            "time_total_s: 575.0308880805969\n",
            "timestamp: 1553484075\n",
            "timesteps_since_restore: 177700\n",
            "timesteps_this_iter: 3200\n",
            "timesteps_total: 177700\n",
            "training_iteration: 55\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-21-26\n",
            "done: false\n",
            "episode_len_mean: 365.57\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 9.47\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 11\n",
            "episodes_total: 794\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 551.0440063476562\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0014075625222176313\n",
            "    mean_KL: 8.10090423328802e-05\n",
            "    median_KL: 5.0445358112938266e-08\n",
            "    model: {}\n",
            "    policy_loss: -35.451141357421875\n",
            "    var_gnorm: 12.561872482299805\n",
            "    vf_explained_var: 0.5515720844268799\n",
            "    vf_loss: 39.80885696411133\n",
            "  learner_queue:\n",
            "    size_count: 362\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 181050\n",
            "  num_steps_trained: 181000\n",
            "  num_weight_syncs: 3621\n",
            "  sample_throughput: 320.504\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1414.837\n",
            "    learner_grad_time_ms: 142.648\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.703\n",
            "  train_throughput: 334.855\n",
            "iterations_since_restore: 56\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 585.4711678028107\n",
            "time_this_iter_s: 10.440279722213745\n",
            "time_total_s: 585.4711678028107\n",
            "timestamp: 1553484086\n",
            "timesteps_since_restore: 181050\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 181050\n",
            "training_iteration: 56\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-21-36\n",
            "done: false\n",
            "episode_len_mean: 372.7\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 9.62\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 802\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 543.7579956054688\n",
            "    grad_gnorm: 40.00000762939453\n",
            "    max_KL: 0.0015985844656825066\n",
            "    mean_KL: 0.00010657406528480351\n",
            "    median_KL: 5.0622801950339635e-08\n",
            "    model: {}\n",
            "    policy_loss: -25.24120330810547\n",
            "    var_gnorm: 12.607932090759277\n",
            "    vf_explained_var: 0.5014864206314087\n",
            "    vf_loss: 44.549949645996094\n",
            "  learner_queue:\n",
            "    size_count: 368\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 184400\n",
            "  num_steps_trained: 184000\n",
            "  num_weight_syncs: 3688\n",
            "  sample_throughput: 323.481\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1413.419\n",
            "    learner_grad_time_ms: 139.612\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.298\n",
            "  train_throughput: 289.685\n",
            "iterations_since_restore: 57\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 595.81543135643\n",
            "time_this_iter_s: 10.344263553619385\n",
            "time_total_s: 595.81543135643\n",
            "timestamp: 1553484096\n",
            "timesteps_since_restore: 184400\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 184400\n",
            "training_iteration: 57\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-21-47\n",
            "done: false\n",
            "episode_len_mean: 378.12\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 9.85\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 9\n",
            "episodes_total: 811\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 525.03759765625\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.004647612571716309\n",
            "    mean_KL: 0.00012714807235170156\n",
            "    median_KL: 1.6575340566760133e-07\n",
            "    model: {}\n",
            "    policy_loss: -17.573883056640625\n",
            "    var_gnorm: 12.660036087036133\n",
            "    vf_explained_var: 0.5887948870658875\n",
            "    vf_loss: 28.293415069580078\n",
            "  learner_queue:\n",
            "    size_count: 375\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 187750\n",
            "  num_steps_trained: 187500\n",
            "  num_weight_syncs: 3755\n",
            "  sample_throughput: 323.04\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1414.828\n",
            "    learner_grad_time_ms: 141.414\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.541\n",
            "  train_throughput: 337.505\n",
            "iterations_since_restore: 58\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 606.1744935512543\n",
            "time_this_iter_s: 10.359062194824219\n",
            "time_total_s: 606.1744935512543\n",
            "timestamp: 1553484107\n",
            "timesteps_since_restore: 187750\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 187750\n",
            "training_iteration: 58\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-21-57\n",
            "done: false\n",
            "episode_len_mean: 381.61\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 10.21\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 9\n",
            "episodes_total: 820\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 526.3944091796875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0011777784675359726\n",
            "    mean_KL: 3.46750566677656e-05\n",
            "    median_KL: 1.611314530691743e-07\n",
            "    model: {}\n",
            "    policy_loss: -39.975032806396484\n",
            "    var_gnorm: 12.70080280303955\n",
            "    vf_explained_var: 0.6070224046707153\n",
            "    vf_loss: 30.53443145751953\n",
            "  learner_queue:\n",
            "    size_count: 382\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 191100\n",
            "  num_steps_trained: 191000\n",
            "  num_weight_syncs: 3822\n",
            "  sample_throughput: 320.848\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1411.704\n",
            "    learner_grad_time_ms: 143.649\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.792\n",
            "  train_throughput: 335.215\n",
            "iterations_since_restore: 59\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 616.6048560142517\n",
            "time_this_iter_s: 10.430362462997437\n",
            "time_total_s: 616.6048560142517\n",
            "timestamp: 1553484117\n",
            "timesteps_since_restore: 191100\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 191100\n",
            "training_iteration: 59\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-22-08\n",
            "done: false\n",
            "episode_len_mean: 389.32\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 10.54\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 828\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 522.2222900390625\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0031341630965471268\n",
            "    mean_KL: 0.0001293064997298643\n",
            "    median_KL: 1.6898697197120782e-07\n",
            "    model: {}\n",
            "    policy_loss: -41.520137786865234\n",
            "    var_gnorm: 12.740547180175781\n",
            "    vf_explained_var: 0.6483783721923828\n",
            "    vf_loss: 22.785764694213867\n",
            "  learner_queue:\n",
            "    size_count: 389\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 194500\n",
            "  num_steps_trained: 194000\n",
            "  num_weight_syncs: 3890\n",
            "  sample_throughput: 322.584\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1398.548\n",
            "    learner_grad_time_ms: 146.575\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.721\n",
            "  train_throughput: 284.633\n",
            "iterations_since_restore: 60\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 627.1341392993927\n",
            "time_this_iter_s: 10.529283285140991\n",
            "time_total_s: 627.1341392993927\n",
            "timestamp: 1553484128\n",
            "timesteps_since_restore: 194500\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 194500\n",
            "training_iteration: 60\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-22-18\n",
            "done: false\n",
            "episode_len_mean: 397.18\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 10.73\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 7\n",
            "episodes_total: 835\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 525.83984375\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0018676817417144775\n",
            "    mean_KL: 8.32668665680103e-05\n",
            "    median_KL: 2.3143218186305603e-07\n",
            "    model: {}\n",
            "    policy_loss: 58.67106628417969\n",
            "    var_gnorm: 12.774096488952637\n",
            "    vf_explained_var: 0.47355347871780396\n",
            "    vf_loss: 43.35776901245117\n",
            "  learner_queue:\n",
            "    size_count: 395\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 197850\n",
            "  num_steps_trained: 197500\n",
            "  num_weight_syncs: 3957\n",
            "  sample_throughput: 325.071\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1422.363\n",
            "    learner_grad_time_ms: 144.717\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.004\n",
            "  train_throughput: 339.627\n",
            "iterations_since_restore: 61\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 637.4276907444\n",
            "time_this_iter_s: 10.293551445007324\n",
            "time_total_s: 637.4276907444\n",
            "timestamp: 1553484138\n",
            "timesteps_since_restore: 197850\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 197850\n",
            "training_iteration: 61\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-22-28\n",
            "done: false\n",
            "episode_len_mean: 405.65\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.17\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 843\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 498.83795166015625\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.001139707863330841\n",
            "    mean_KL: 7.93946601334028e-05\n",
            "    median_KL: 1.6865169527591206e-07\n",
            "    model: {}\n",
            "    policy_loss: -3.073242664337158\n",
            "    var_gnorm: 12.815080642700195\n",
            "    vf_explained_var: 0.5522128343582153\n",
            "    vf_loss: 43.25401306152344\n",
            "  learner_queue:\n",
            "    size_count: 402\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 201250\n",
            "  num_steps_trained: 201000\n",
            "  num_weight_syncs: 4025\n",
            "  sample_throughput: 323.518\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1413.357\n",
            "    learner_grad_time_ms: 139.57\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.997\n",
            "  train_throughput: 333.033\n",
            "iterations_since_restore: 62\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 647.9249136447906\n",
            "time_this_iter_s: 10.497222900390625\n",
            "time_total_s: 647.9249136447906\n",
            "timestamp: 1553484148\n",
            "timesteps_since_restore: 201250\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 201250\n",
            "training_iteration: 62\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-22-39\n",
            "done: false\n",
            "episode_len_mean: 413.79\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.6\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 7\n",
            "episodes_total: 850\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 503.45269775390625\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.002112293615937233\n",
            "    mean_KL: 0.00018504509353078902\n",
            "    median_KL: 5.8588529583403215e-08\n",
            "    model: {}\n",
            "    policy_loss: 18.046146392822266\n",
            "    var_gnorm: 12.85591983795166\n",
            "    vf_explained_var: 0.39871764183044434\n",
            "    vf_loss: 44.439613342285156\n",
            "  learner_queue:\n",
            "    size_count: 409\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 204650\n",
            "  num_steps_trained: 204500\n",
            "  num_weight_syncs: 4093\n",
            "  sample_throughput: 324.117\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1380.568\n",
            "    learner_grad_time_ms: 144.031\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.544\n",
            "  train_throughput: 333.65\n",
            "iterations_since_restore: 63\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 658.4001762866974\n",
            "time_this_iter_s: 10.475262641906738\n",
            "time_total_s: 658.4001762866974\n",
            "timestamp: 1553484159\n",
            "timesteps_since_restore: 204650\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 204650\n",
            "training_iteration: 63\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-22-49\n",
            "done: false\n",
            "episode_len_mean: 420.55\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.92\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 860\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 507.5755310058594\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0014979252591729164\n",
            "    mean_KL: 0.00011696856381604448\n",
            "    median_KL: 2.1451563725349843e-07\n",
            "    model: {}\n",
            "    policy_loss: -54.959877014160156\n",
            "    var_gnorm: 12.89267349243164\n",
            "    vf_explained_var: 0.30286985635757446\n",
            "    vf_loss: 49.884517669677734\n",
            "  learner_queue:\n",
            "    size_count: 416\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 208050\n",
            "  num_steps_trained: 208000\n",
            "  num_weight_syncs: 4161\n",
            "  sample_throughput: 323.819\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1394.796\n",
            "    learner_grad_time_ms: 142.886\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 20.38\n",
            "  train_throughput: 333.343\n",
            "iterations_since_restore: 64\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 668.8882057666779\n",
            "time_this_iter_s: 10.488029479980469\n",
            "time_total_s: 668.8882057666779\n",
            "timestamp: 1553484169\n",
            "timesteps_since_restore: 208050\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 208050\n",
            "training_iteration: 64\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-23-00\n",
            "done: false\n",
            "episode_len_mean: 422.08\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.78\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 9\n",
            "episodes_total: 869\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 526.5640869140625\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.006353878416121006\n",
            "    mean_KL: 0.00037472115946002305\n",
            "    median_KL: 1.5344433279551595e-07\n",
            "    model: {}\n",
            "    policy_loss: 60.30713653564453\n",
            "    var_gnorm: 12.915302276611328\n",
            "    vf_explained_var: 0.4843136668205261\n",
            "    vf_loss: 34.6533203125\n",
            "  learner_queue:\n",
            "    size_count: 422\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 211450\n",
            "  num_steps_trained: 211000\n",
            "  num_weight_syncs: 4229\n",
            "  sample_throughput: 323.292\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1416.734\n",
            "    learner_grad_time_ms: 137.841\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.825\n",
            "  train_throughput: 285.258\n",
            "iterations_since_restore: 65\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 679.3942382335663\n",
            "time_this_iter_s: 10.506032466888428\n",
            "time_total_s: 679.3942382335663\n",
            "timestamp: 1553484180\n",
            "timesteps_since_restore: 211450\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 211450\n",
            "training_iteration: 65\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-23-10\n",
            "done: false\n",
            "episode_len_mean: 423.63\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.71\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 877\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 554.3294067382812\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.001691044308245182\n",
            "    mean_KL: 9.138235327554867e-05\n",
            "    median_KL: 5.267270353215281e-08\n",
            "    model: {}\n",
            "    policy_loss: 27.42705726623535\n",
            "    var_gnorm: 12.944766998291016\n",
            "    vf_explained_var: 0.5650331974029541\n",
            "    vf_loss: 29.66576385498047\n",
            "  learner_queue:\n",
            "    size_count: 429\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 214800\n",
            "  num_steps_trained: 214500\n",
            "  num_weight_syncs: 4296\n",
            "  sample_throughput: 320.572\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1407.751\n",
            "    learner_grad_time_ms: 141.186\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.712\n",
            "  train_throughput: 334.926\n",
            "iterations_since_restore: 66\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 689.8326678276062\n",
            "time_this_iter_s: 10.438429594039917\n",
            "time_total_s: 689.8326678276062\n",
            "timestamp: 1553484190\n",
            "timesteps_since_restore: 214800\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 214800\n",
            "training_iteration: 66\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-23-21\n",
            "done: false\n",
            "episode_len_mean: 421.5\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.55\n",
            "episode_reward_min: 3.0\n",
            "episodes_this_iter: 10\n",
            "episodes_total: 887\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 549.2407836914062\n",
            "    grad_gnorm: 39.999996185302734\n",
            "    max_KL: 0.002914685755968094\n",
            "    mean_KL: 0.0001685198221821338\n",
            "    median_KL: 5.3160000845764444e-08\n",
            "    model: {}\n",
            "    policy_loss: -36.07440948486328\n",
            "    var_gnorm: 12.993566513061523\n",
            "    vf_explained_var: 0.5979017019271851\n",
            "    vf_loss: 34.54688262939453\n",
            "  learner_queue:\n",
            "    size_count: 436\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 218150\n",
            "  num_steps_trained: 218000\n",
            "  num_weight_syncs: 4363\n",
            "  sample_throughput: 321.566\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1417.872\n",
            "    learner_grad_time_ms: 140.169\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.65\n",
            "  train_throughput: 335.964\n",
            "iterations_since_restore: 67\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 700.2383105754852\n",
            "time_this_iter_s: 10.405642747879028\n",
            "time_total_s: 700.2383105754852\n",
            "timestamp: 1553484201\n",
            "timesteps_since_restore: 218150\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 218150\n",
            "training_iteration: 67\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-23-31\n",
            "done: false\n",
            "episode_len_mean: 426.49\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.77\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 895\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 541.588623046875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0011032149195671082\n",
            "    mean_KL: 9.698566282168031e-05\n",
            "    median_KL: 6.136532704204001e-08\n",
            "    model: {}\n",
            "    policy_loss: -46.76971435546875\n",
            "    var_gnorm: 13.040441513061523\n",
            "    vf_explained_var: 0.6615102291107178\n",
            "    vf_loss: 28.014114379882812\n",
            "  learner_queue:\n",
            "    size_count: 443\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 221550\n",
            "  num_steps_trained: 221500\n",
            "  num_weight_syncs: 4431\n",
            "  sample_throughput: 325.369\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1395.072\n",
            "    learner_grad_time_ms: 152.95\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 16.471\n",
            "  train_throughput: 334.938\n",
            "iterations_since_restore: 68\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 710.674576997757\n",
            "time_this_iter_s: 10.436266422271729\n",
            "time_total_s: 710.674576997757\n",
            "timestamp: 1553484211\n",
            "timesteps_since_restore: 221550\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 221550\n",
            "training_iteration: 68\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-23-42\n",
            "done: false\n",
            "episode_len_mean: 425.7\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.87\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 9\n",
            "episodes_total: 904\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 556.5587768554688\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0025992020964622498\n",
            "    mean_KL: 0.00010192779154749587\n",
            "    median_KL: 5.396677948965589e-08\n",
            "    model: {}\n",
            "    policy_loss: 40.66591262817383\n",
            "    var_gnorm: 13.07466983795166\n",
            "    vf_explained_var: 0.5302003622055054\n",
            "    vf_loss: 29.11610984802246\n",
            "  learner_queue:\n",
            "    size_count: 449\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 224950\n",
            "  num_steps_trained: 224500\n",
            "  num_weight_syncs: 4499\n",
            "  sample_throughput: 325.301\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1382.056\n",
            "    learner_grad_time_ms: 149.917\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.159\n",
            "  train_throughput: 287.03\n",
            "iterations_since_restore: 69\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 721.114660024643\n",
            "time_this_iter_s: 10.440083026885986\n",
            "time_total_s: 721.114660024643\n",
            "timestamp: 1553484222\n",
            "timesteps_since_restore: 224950\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 224950\n",
            "training_iteration: 69\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-23-52\n",
            "done: false\n",
            "episode_len_mean: 426.65\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 11.99\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 912\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 543.4354858398438\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.003530709072947502\n",
            "    mean_KL: 0.0001538657525088638\n",
            "    median_KL: 5.271378711313446e-08\n",
            "    model: {}\n",
            "    policy_loss: 27.560169219970703\n",
            "    var_gnorm: 13.120657920837402\n",
            "    vf_explained_var: 0.667736291885376\n",
            "    vf_loss: 24.919939041137695\n",
            "  learner_queue:\n",
            "    size_count: 456\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 228300\n",
            "  num_steps_trained: 228000\n",
            "  num_weight_syncs: 4566\n",
            "  sample_throughput: 323.269\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1399.956\n",
            "    learner_grad_time_ms: 141.586\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.155\n",
            "  train_throughput: 337.744\n",
            "iterations_since_restore: 70\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 731.4651441574097\n",
            "time_this_iter_s: 10.350484132766724\n",
            "time_total_s: 731.4651441574097\n",
            "timestamp: 1553484232\n",
            "timesteps_since_restore: 228300\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 228300\n",
            "training_iteration: 70\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-24-02\n",
            "done: false\n",
            "episode_len_mean: 432.52\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 12.15\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 920\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 553.1138916015625\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0008990759961307049\n",
            "    mean_KL: 4.108672510483302e-05\n",
            "    median_KL: 5.645188139169477e-08\n",
            "    model: {}\n",
            "    policy_loss: 71.28054809570312\n",
            "    var_gnorm: 13.166810035705566\n",
            "    vf_explained_var: 0.49508482217788696\n",
            "    vf_loss: 41.01591873168945\n",
            "  learner_queue:\n",
            "    size_count: 463\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 231650\n",
            "  num_steps_trained: 231500\n",
            "  num_weight_syncs: 4633\n",
            "  sample_throughput: 323.013\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1395.806\n",
            "    learner_grad_time_ms: 138.623\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.179\n",
            "  train_throughput: 337.476\n",
            "iterations_since_restore: 71\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 741.8231163024902\n",
            "time_this_iter_s: 10.357972145080566\n",
            "time_total_s: 741.8231163024902\n",
            "timestamp: 1553484242\n",
            "timesteps_since_restore: 231650\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 231650\n",
            "training_iteration: 71\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-24-13\n",
            "done: false\n",
            "episode_len_mean: 432.05\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 12.14\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 928\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 543.9419555664062\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0019539776258170605\n",
            "    mean_KL: 0.00010646028385963291\n",
            "    median_KL: 5.658302981714769e-08\n",
            "    model: {}\n",
            "    policy_loss: 65.93421173095703\n",
            "    var_gnorm: 13.215216636657715\n",
            "    vf_explained_var: 0.5890321731567383\n",
            "    vf_loss: 37.215362548828125\n",
            "  learner_queue:\n",
            "    size_count: 470\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 235000\n",
            "  num_steps_trained: 235000\n",
            "  num_weight_syncs: 4700\n",
            "  sample_throughput: 322.867\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1410.637\n",
            "    learner_grad_time_ms: 136.528\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.433\n",
            "  train_throughput: 337.324\n",
            "iterations_since_restore: 72\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 752.1876990795135\n",
            "time_this_iter_s: 10.364582777023315\n",
            "time_total_s: 752.1876990795135\n",
            "timestamp: 1553484253\n",
            "timesteps_since_restore: 235000\n",
            "timesteps_this_iter: 3350\n",
            "timesteps_total: 235000\n",
            "training_iteration: 72\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-24-23\n",
            "done: false\n",
            "episode_len_mean: 426.94\n",
            "episode_reward_max: 25.0\n",
            "episode_reward_mean: 12.09\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 936\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 538.3970947265625\n",
            "    grad_gnorm: 39.99999237060547\n",
            "    max_KL: 0.0025981273502111435\n",
            "    mean_KL: 8.655141573399305e-05\n",
            "    median_KL: 5.334883468322005e-08\n",
            "    model: {}\n",
            "    policy_loss: 45.5831184387207\n",
            "    var_gnorm: 13.258252143859863\n",
            "    vf_explained_var: 0.6257286667823792\n",
            "    vf_loss: 31.253868103027344\n",
            "  learner_queue:\n",
            "    size_count: 476\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 238400\n",
            "  num_steps_trained: 238000\n",
            "  num_weight_syncs: 4768\n",
            "  sample_throughput: 323.279\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1407.872\n",
            "    learner_grad_time_ms: 137.683\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 16.48\n",
            "  train_throughput: 285.247\n",
            "iterations_since_restore: 73\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 762.6934134960175\n",
            "time_this_iter_s: 10.505714416503906\n",
            "time_total_s: 762.6934134960175\n",
            "timestamp: 1553484263\n",
            "timesteps_since_restore: 238400\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 238400\n",
            "training_iteration: 73\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-24-34\n",
            "done: false\n",
            "episode_len_mean: 430.47\n",
            "episode_reward_max: 21.0\n",
            "episode_reward_mean: 12.28\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 944\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 527.8311767578125\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0026993444189429283\n",
            "    mean_KL: 0.00022670056205242872\n",
            "    median_KL: 4.822152277483838e-08\n",
            "    model: {}\n",
            "    policy_loss: 2.0923209190368652\n",
            "    var_gnorm: 13.31167221069336\n",
            "    vf_explained_var: 0.5833502411842346\n",
            "    vf_loss: 34.1765251159668\n",
            "  learner_queue:\n",
            "    size_count: 483\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 241800\n",
            "  num_steps_trained: 241500\n",
            "  num_weight_syncs: 4836\n",
            "  sample_throughput: 328.031\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1401.181\n",
            "    learner_grad_time_ms: 137.905\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.138\n",
            "  train_throughput: 337.679\n",
            "iterations_since_restore: 74\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 773.0477645397186\n",
            "time_this_iter_s: 10.354351043701172\n",
            "time_total_s: 773.0477645397186\n",
            "timestamp: 1553484274\n",
            "timesteps_since_restore: 241800\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 241800\n",
            "training_iteration: 74\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-24-44\n",
            "done: false\n",
            "episode_len_mean: 433.49\n",
            "episode_reward_max: 21.0\n",
            "episode_reward_mean: 12.28\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 6\n",
            "episodes_total: 950\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 503.4320373535156\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0025047417730093002\n",
            "    mean_KL: 6.382226274581626e-05\n",
            "    median_KL: 5.977511108312683e-08\n",
            "    model: {}\n",
            "    policy_loss: -86.41438293457031\n",
            "    var_gnorm: 13.363216400146484\n",
            "    vf_explained_var: 0.6100409626960754\n",
            "    vf_loss: 38.25191116333008\n",
            "  learner_queue:\n",
            "    size_count: 490\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 245200\n",
            "  num_steps_trained: 245000\n",
            "  num_weight_syncs: 4904\n",
            "  sample_throughput: 326.529\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1385.602\n",
            "    learner_grad_time_ms: 139.662\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.26\n",
            "  train_throughput: 336.133\n",
            "iterations_since_restore: 75\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 783.4499037265778\n",
            "time_this_iter_s: 10.40213918685913\n",
            "time_total_s: 783.4499037265778\n",
            "timestamp: 1553484284\n",
            "timesteps_since_restore: 245200\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 245200\n",
            "training_iteration: 75\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-24-54\n",
            "done: false\n",
            "episode_len_mean: 438.05\n",
            "episode_reward_max: 19.0\n",
            "episode_reward_mean: 12.25\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 958\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 519.904052734375\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0007300120778381824\n",
            "    mean_KL: 3.200965511496179e-05\n",
            "    median_KL: 5.0579799903971434e-08\n",
            "    model: {}\n",
            "    policy_loss: -32.11540603637695\n",
            "    var_gnorm: 13.400806427001953\n",
            "    vf_explained_var: 0.722751259803772\n",
            "    vf_loss: 25.513507843017578\n",
            "  learner_queue:\n",
            "    size_count: 497\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 248600\n",
            "  num_steps_trained: 248500\n",
            "  num_weight_syncs: 4972\n",
            "  sample_throughput: 326.214\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1393.479\n",
            "    learner_grad_time_ms: 142.459\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.164\n",
            "  train_throughput: 335.808\n",
            "iterations_since_restore: 76\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 793.8614492416382\n",
            "time_this_iter_s: 10.411545515060425\n",
            "time_total_s: 793.8614492416382\n",
            "timestamp: 1553484294\n",
            "timesteps_since_restore: 248600\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 248600\n",
            "training_iteration: 76\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-25-05\n",
            "done: false\n",
            "episode_len_mean: 445.93\n",
            "episode_reward_max: 19.0\n",
            "episode_reward_mean: 12.47\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 966\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 524.6651611328125\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0018040426075458527\n",
            "    mean_KL: 0.00012136308941990137\n",
            "    median_KL: 1.8839301674233866e-07\n",
            "    model: {}\n",
            "    policy_loss: -33.03734588623047\n",
            "    var_gnorm: 13.432792663574219\n",
            "    vf_explained_var: 0.8124815821647644\n",
            "    vf_loss: 18.187650680541992\n",
            "  learner_queue:\n",
            "    size_count: 504\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 252000\n",
            "  num_steps_trained: 251500\n",
            "  num_weight_syncs: 5040\n",
            "  sample_throughput: 325.774\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1399.051\n",
            "    learner_grad_time_ms: 139.297\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.675\n",
            "  train_throughput: 287.447\n",
            "iterations_since_restore: 77\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 804.2829399108887\n",
            "time_this_iter_s: 10.421490669250488\n",
            "time_total_s: 804.2829399108887\n",
            "timestamp: 1553484305\n",
            "timesteps_since_restore: 252000\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 252000\n",
            "training_iteration: 77\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-25-15\n",
            "done: false\n",
            "episode_len_mean: 450.11\n",
            "episode_reward_max: 29.0\n",
            "episode_reward_mean: 12.88\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 7\n",
            "episodes_total: 973\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 514.46044921875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.005036264657974243\n",
            "    mean_KL: 0.00021625313092954457\n",
            "    median_KL: 5.3478807160445285e-08\n",
            "    model: {}\n",
            "    policy_loss: 4.470713138580322\n",
            "    var_gnorm: 13.456991195678711\n",
            "    vf_explained_var: 0.7619665861129761\n",
            "    vf_loss: 19.460718154907227\n",
            "  learner_queue:\n",
            "    size_count: 510\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 255400\n",
            "  num_steps_trained: 255000\n",
            "  num_weight_syncs: 5108\n",
            "  sample_throughput: 326.259\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1387.322\n",
            "    learner_grad_time_ms: 147.661\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.02\n",
            "  train_throughput: 335.855\n",
            "iterations_since_restore: 78\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 814.6898324489594\n",
            "time_this_iter_s: 10.406892538070679\n",
            "time_total_s: 814.6898324489594\n",
            "timestamp: 1553484315\n",
            "timesteps_since_restore: 255400\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 255400\n",
            "training_iteration: 78\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-25-26\n",
            "done: false\n",
            "episode_len_mean: 456.74\n",
            "episode_reward_max: 29.0\n",
            "episode_reward_mean: 13.15\n",
            "episode_reward_min: 4.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 981\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 529.9246826171875\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0015137139707803726\n",
            "    mean_KL: 8.024273120099679e-05\n",
            "    median_KL: 4.777725948201805e-08\n",
            "    model: {}\n",
            "    policy_loss: 43.1152229309082\n",
            "    var_gnorm: 13.487191200256348\n",
            "    vf_explained_var: 0.5349572896957397\n",
            "    vf_loss: 38.37690734863281\n",
            "  learner_queue:\n",
            "    size_count: 517\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 258800\n",
            "  num_steps_trained: 258500\n",
            "  num_weight_syncs: 5176\n",
            "  sample_throughput: 323.642\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1385.888\n",
            "    learner_grad_time_ms: 139.238\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 13.244\n",
            "  train_throughput: 333.161\n",
            "iterations_since_restore: 79\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 825.182626247406\n",
            "time_this_iter_s: 10.492793798446655\n",
            "time_total_s: 825.182626247406\n",
            "timestamp: 1553484326\n",
            "timesteps_since_restore: 258800\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 258800\n",
            "training_iteration: 79\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-25-36\n",
            "done: false\n",
            "episode_len_mean: 462.61\n",
            "episode_reward_max: 29.0\n",
            "episode_reward_mean: 13.53\n",
            "episode_reward_min: 5.0\n",
            "episodes_this_iter: 6\n",
            "episodes_total: 987\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 530.82275390625\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.001955285668373108\n",
            "    mean_KL: 9.416480315849185e-05\n",
            "    median_KL: 6.550020259510347e-08\n",
            "    model: {}\n",
            "    policy_loss: 10.372386932373047\n",
            "    var_gnorm: 13.516507148742676\n",
            "    vf_explained_var: 0.5147184133529663\n",
            "    vf_loss: 35.405372619628906\n",
            "  learner_queue:\n",
            "    size_count: 524\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 262200\n",
            "  num_steps_trained: 262000\n",
            "  num_weight_syncs: 5244\n",
            "  sample_throughput: 326.387\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1399.075\n",
            "    learner_grad_time_ms: 128.404\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 11.341\n",
            "  train_throughput: 335.986\n",
            "iterations_since_restore: 80\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 835.5885338783264\n",
            "time_this_iter_s: 10.40590763092041\n",
            "time_total_s: 835.5885338783264\n",
            "timestamp: 1553484336\n",
            "timesteps_since_restore: 262200\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 262200\n",
            "training_iteration: 80\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-25-47\n",
            "done: false\n",
            "episode_len_mean: 469.63\n",
            "episode_reward_max: 29.0\n",
            "episode_reward_mean: 13.72\n",
            "episode_reward_min: 5.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 995\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 507.7500915527344\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.008371945470571518\n",
            "    mean_KL: 0.00038016121834516525\n",
            "    median_KL: 5.3132417576762236e-08\n",
            "    model: {}\n",
            "    policy_loss: 1.0137659311294556\n",
            "    var_gnorm: 13.547465324401855\n",
            "    vf_explained_var: 0.4647337794303894\n",
            "    vf_loss: 53.488338470458984\n",
            "  learner_queue:\n",
            "    size_count: 531\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 265600\n",
            "  num_steps_trained: 265500\n",
            "  num_weight_syncs: 5312\n",
            "  sample_throughput: 324.334\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1402.474\n",
            "    learner_grad_time_ms: 140.413\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 15.396\n",
            "  train_throughput: 333.873\n",
            "iterations_since_restore: 81\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 846.0602624416351\n",
            "time_this_iter_s: 10.471728563308716\n",
            "time_total_s: 846.0602624416351\n",
            "timestamp: 1553484347\n",
            "timesteps_since_restore: 265600\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 265600\n",
            "training_iteration: 81\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-25-57\n",
            "done: false\n",
            "episode_len_mean: 476.5\n",
            "episode_reward_max: 29.0\n",
            "episode_reward_mean: 13.92\n",
            "episode_reward_min: 5.0\n",
            "episodes_this_iter: 6\n",
            "episodes_total: 1001\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 516.9854125976562\n",
            "    grad_gnorm: 40.000003814697266\n",
            "    max_KL: 0.0013070087879896164\n",
            "    mean_KL: 0.00010041220230050385\n",
            "    median_KL: 1.9509644744175603e-07\n",
            "    model: {}\n",
            "    policy_loss: 82.95726776123047\n",
            "    var_gnorm: 13.571218490600586\n",
            "    vf_explained_var: 0.6280524730682373\n",
            "    vf_loss: 29.29792594909668\n",
            "  learner_queue:\n",
            "    size_count: 538\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 269000\n",
            "  num_steps_trained: 268500\n",
            "  num_weight_syncs: 5380\n",
            "  sample_throughput: 326.872\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1390.519\n",
            "    learner_grad_time_ms: 148.265\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 18.783\n",
            "  train_throughput: 288.416\n",
            "iterations_since_restore: 82\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 856.4515070915222\n",
            "time_this_iter_s: 10.391244649887085\n",
            "time_total_s: 856.4515070915222\n",
            "timestamp: 1553484357\n",
            "timesteps_since_restore: 269000\n",
            "timesteps_this_iter: 3400\n",
            "timesteps_total: 269000\n",
            "training_iteration: 82\n",
            "\n",
            "custom_metrics: {}\n",
            "date: 2019-03-25_03-26-08\n",
            "done: false\n",
            "episode_len_mean: 482.82\n",
            "episode_reward_max: 29.0\n",
            "episode_reward_mean: 14.26\n",
            "episode_reward_min: 5.0\n",
            "episodes_this_iter: 8\n",
            "episodes_total: 1009\n",
            "experiment_id: 7d8b7b53fcf743bb8fe8f167daf72824\n",
            "hostname: 228cabdf7ba8\n",
            "info:\n",
            "  learner:\n",
            "    cur_lr: 0.0005000000237487257\n",
            "    entropy: 495.936767578125\n",
            "    grad_gnorm: 40.0\n",
            "    max_KL: 0.0008716722950339317\n",
            "    mean_KL: 4.823155177291483e-05\n",
            "    median_KL: 5.692547233593359e-08\n",
            "    model: {}\n",
            "    policy_loss: -49.53618240356445\n",
            "    var_gnorm: 13.592146873474121\n",
            "    vf_explained_var: 0.5495755672454834\n",
            "    vf_loss: 49.61506271362305\n",
            "  learner_queue:\n",
            "    size_count: 544\n",
            "    size_mean: 0.0\n",
            "    size_quantiles:\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    - 0.0\n",
            "    size_std: 0.0\n",
            "  num_steps_replayed: 0\n",
            "  num_steps_sampled: 272450\n",
            "  num_steps_trained: 272000\n",
            "  num_weight_syncs: 5449\n",
            "  sample_throughput: 327.781\n",
            "  timing_breakdown:\n",
            "    learner_dequeue_time_ms: 1373.392\n",
            "    learner_grad_time_ms: 148.415\n",
            "    learner_load_time_ms: .nan\n",
            "    learner_load_wait_time_ms: .nan\n",
            "    optimizer_step_time_ms: 14.773\n",
            "  train_throughput: 332.532\n",
            "iterations_since_restore: 83\n",
            "node_ip: 172.28.0.2\n",
            "num_metric_batches_dropped: 0\n",
            "off_policy_estimator: {}\n",
            "pid: 206\n",
            "policy_reward_mean: {}\n",
            "time_since_restore: 866.9665236473083\n",
            "time_this_iter_s: 10.515016555786133\n",
            "time_total_s: 866.9665236473083\n",
            "timestamp: 1553484368\n",
            "timesteps_since_restore: 272450\n",
            "timesteps_this_iter: 3450\n",
            "timesteps_total: 272450\n",
            "training_iteration: 83\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}